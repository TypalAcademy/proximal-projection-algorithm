{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Proximal Projection Algorithm","text":"<p>This website documents code used in the paper Proximal Projection Method for Stable Linearly Constrained Optimization.</p> <p> <p>arXiv Prerint  Github Repo </p> <p></p>"},{"location":"#abstract","title":"Abstract","text":"<p>Many applications using large datasets require efficient methods for minimizing a proximable convex function subject to satisfying a set of linear constraints within a specified tolerance. For this task, we present a proximal projection (PP) algorithm, which is an instance of Douglas-Rachford splitting that directly uses projections onto the set of constraints. Formal guarantees are presented to prove convergence of PP estimates to optimizers. Unlike many methods that obtain feasibility asymptotically, each PP iterate is feasible. Numerically, we show PP either matches or outperforms alternatives (e.g. linearized Bregman, primal dual hybrid gradient, proximal augmented Lagrangian, proximal gradient) on problems in basis pursuit, stable matrix completion, stable principal component pursuit, and the computation of earth mover's distances.</p>"},{"location":"#key-results","title":"Key Results","text":"<p>Problem: For a convex function \\(\\mathsf{f\\colon\\mathbb{R}^n \\rightarrow \\overline{\\mathbb{R}}}\\), a matrix \\(\\mathsf{A \\in \\mathbb{R}^{m\\times n}}\\), a vector \\(\\mathsf{b\\in \\mathbb{R}^m}\\), and a scalar \\(\\mathsf{\\varepsilon \\geq 0}\\), we consider the problem</p> \\[ \\mathsf{   \\underset{x}{\\mathsf{min}} \\ f(x) \\quad\\mathsf{s.t.}\\quad \\|Ax-b\\|\\leq \\varepsilon. } \\] <p>We refer to this as a stable linearly constrained optimization problem and below set \\(\\mathsf{\\mathcal{C} = \\{ x : \\|Ax-b\\|\\leq\\varepsilon\\}}\\). The key conditions used in this work are as follows.</p> <ul> <li> the function \\(\\mathsf{f\\colon\\mathbb{R}^n\\rightarrow \\overline{\\mathbb{R}}}\\) is closed, convex, and proper;</li> <li> either the matrix \\(\\mathsf{A}\\) has full row-rank or \\(\\mathsf{\\varepsilon &gt; 0}\\);</li> <li> there is \\(\\mathsf{y \\in \\mathbb{R}^n}\\) such that, if \\(\\mathsf{\\varepsilon = 0}\\), then \\(\\mathsf{Ay = b}\\) and, if \\(\\mathsf{\\varepsilon &gt; 0}\\), then  \\(\\mathsf{\\|Ay-b\\| &lt; \\varepsilon}\\); </li> <li> the above condition holds for \\(\\mathsf{y \\in \\mbox{ri}(\\mbox{dom}(f))}\\).    </li> <li> either \\(\\mathsf{f}\\) is coercive or \\(\\mathcal{C}\\) is bounded; </li> </ul> <p>Proposition: If the conditions above hold, then projection onto \\(\\mathcal{C}\\) is given by</p> \\[ \\mathsf{proj_{\\mathcal{C}}(x)} = \\begin{cases}     \\begin{array}{cl}         \\mathsf{x} &amp; \\mathsf{if\\ \\|Ax-b\\|\\leq\\varepsilon,} \\\\         \\mathsf{x - A^\\top(AA^\\top +\\varepsilon\\tau_x I)^{-1}(Ax-b)} &amp; \\mathsf{otherwise},     \\end{array} \\end{cases} \\] <p>where, if \\(\\mathsf{\\|Ax-b\\|&gt;\\varepsilon}\\), the scalar \\(\\mathsf{\\tau_x}\\) is the unique positive solution to </p> \\[   \\mathsf{1 = \\tau \\| (AA^\\top +\\varepsilon \\tau I)^{-1} (Ax-b) \\|.} \\] <p>Using this projection with Douglas-Rachford Splitting (DRS) yields the PP algorithm below. The output \\(\\mathsf{x}\\) estimates a minimizer to our problem.</p> \\[   \\begin{align}     &amp; \\mathsf{while\\ \\ stopping\\ \\  criteria\\ \\ not\\ \\ met} \\\\     &amp; \\quad\\quad \\mathsf{if \\ \\|Az-b\\|\\leq \\varepsilon} \\\\     &amp; \\quad\\quad\\quad\\quad \\mathsf{x \\leftarrow z} \\\\     &amp; \\quad\\quad \\mathsf{else} \\\\     &amp; \\quad\\quad\\quad\\quad \\mathsf{\\tau \\leftarrow solution\\big( 1 = \\tau \\|AA^\\top + \\varepsilon I)^{-1}(Az-b)} \\\\     &amp; \\quad\\quad\\quad\\quad \\mathsf{x \\leftarrow z - A^\\top (AA^\\top+\\varepsilon I)^{-1}(Az-b) } \\\\     &amp; \\quad\\quad \\mathsf{z \\leftarrow z + prox_{\\alpha f}(2x - z) - x}\\\\     &amp; \\mathsf{return\\ \\ x}   \\end{align} \\] <p>Theorem: If the listed conditions hold, then PP converges to a solution of the stable linearly constrained optimization problem.</p>"},{"location":"#citation","title":"Citation","text":"<pre><code>@article{heaton2024proximal,\n         title={{Proximal Projection Method for Stable Linearly Constrained Optimization}},\n         author={Heaton, Howard},\n         journal={{arXiv preprint}},\n         year={2024}\n}\n</code></pre> <p> Contact Us  </p> <p></p>"},{"location":"basis_pursuit/","title":"Basis Pursuit","text":"<p>This page shows the numerical example for solving the problem</p> \\[     \\mathsf{ \\underset{x}{min} \\ |x|_1 \\quad s.t. \\quad Ax=b. } \\] <p>The proximal for \\(|\\)x\\(|_1\\) is an element-wise shrink operation.</p> Source code in <code>src/basis_pursuit/methods.py</code> <pre><code>def shrink(xi: NDArray[np.float64], alpha: float) -&gt; NDArray[np.float64]:\n    \"\"\"The proximal for $|$x$|_1$ is an element-wise shrink operation.\"\"\"\n    output: NDArray[np.float64] = np.sign(xi) * np.maximum(np.abs(xi) - alpha, 0)\n    return output\n</code></pre>"},{"location":"basis_pursuit/#methods","title":"Methods","text":"<p>The update iteration for each benchmarked algorithm is in Appendix B.1 of the paper. Code implementations are shown below.</p> <p>Proximal Projection</p> Source code in <code>src/basis_pursuit/methods.py</code> <pre><code>def proximal_projection(A, b, alpha=1.0e-1, num_iters=2000):\n    \"\"\"Proximal Projection\"\"\"\n    start = time.time()\n    z = np.zeros((A.shape[1], 1))\n    x = np.zeros((A.shape[1], 1))\n    stats = Stats(matrix=A, measurements=b)\n    AAt = np.linalg.inv(A @ A.T)\n    for _ in range(num_iters):\n        x_p = x.copy()\n        x = z - A.T @ (AAt @ (A @ z - b))\n        z = z + shrink(2.0 * x - z, alpha) - x\n        stats.add_stat(x, x_p)\n    execution_time = time.time() - start\n    return x, stats, execution_time\n</code></pre> <p>Linearized Bregman</p> Source code in <code>src/basis_pursuit/methods.py</code> <pre><code>def linearized_bregman(A, b, mu=2.0, num_iters=2000):\n    \"\"\"Linearized Bregman\"\"\"\n    x = np.zeros((A.shape[1], 1))\n    v = np.zeros((A.shape[1], 1))\n    stats = Stats(matrix=A, measurements=b)\n    start = time.time()\n    matrix_norm = np.linalg.norm(A @ A.T)\n    alpha = 2.0 / matrix_norm\n    mu *= matrix_norm\n    for _ in range(num_iters):\n        x_p = x.copy()\n        v = v - A.T @ (A @ x - b)\n        x = shrink(alpha * v, alpha * mu)\n        stats.add_stat(x, x_p)\n    execution_time = time.time() - start\n    return x, stats, execution_time\n</code></pre> <p>Linearized Method of Multipliers</p> Source code in <code>src/basis_pursuit/methods.py</code> <pre><code>def linearized_method_multipliers(A, b, lambd=100.0, num_iters=2000):\n    \"\"\"Linearized Method of Multipliers\"\"\"\n    rows, cols = A.shape\n    x = np.zeros((cols.shape[1], 1))\n    v = np.zeros((rows.shape[0], 1))\n    stats = Stats(matrix=A, measurements=b)\n    start = time.time()\n    lambd *= np.linalg.norm(A.T @ A)\n    alpha = 1.0 / (lambd * np.linalg.norm(A.T @ A))\n    for _ in range(num_iters):\n        x_p = x.copy()\n        x = shrink(x - alpha * A.T @ (v + lambd * (A @ x - b)), alpha)\n        v = v + lambd * (A @ x - b)\n        stats.add_stat(x, x_p)\n    execution_time = time.time() - start\n    return x, stats, execution_time\n</code></pre> <p>Primal Dual Hybrid Gradient</p> Source code in <code>src/basis_pursuit/methods.py</code> <pre><code>def primal_dual_hybrid_gradient(A, b, lambd=100.0, num_iters=2000):\n    \"\"\"Primal Dual Hybrid Gradient\"\"\"\n    stats = Stats(matrix=A, measurements=b)\n    rows, cols = A.shape\n    x = np.zeros((cols.shape[1], 1))\n    v = np.zeros((rows.shape[0], 1))\n    alpha = 1.0 / (lambd * np.linalg.norm(A.T @ A))\n    start = time.time()\n    for _ in range(num_iters):\n        x_p = x.copy()\n        x = shrink(x - alpha * A.T @ v, alpha)\n        v = v + lambd * (A @ (2 * x - x_p) - b)\n        stats.add_stat(x, x_p)\n    execution_time = time.time() - start\n    return x, stats, execution_time\n</code></pre> <p></p>"},{"location":"basis_pursuit/#experiment","title":"Experiment","text":"<p>The matrix \\(\\mathsf{A \\in \\mathbb{R}^{m\\times n}}\\) i.i.d. Gaussian entries, with \\(\\mathsf{m=500}\\) and \\(\\mathsf{n=2000}\\). Elements of a sparse vector \\(\\mathsf{x^\\star}\\) are independently nonzero with probability \\(\\mathsf{p = 0.05}\\) and the nonzero values are i.i.d. Gaussian. This is used to compute \\(\\mathsf{b = Ax^\\star}\\). Ten trials are executed with distinct random seeds. The mean time for 10 trials of proximal projection, linearized Bregman, primal dual hybrid gradient, and linearized method of multipliers to compute 2,000 iterations were, respectively, 8.06s, 7.40s, 20.60s, and 22.85s.</p> <p>Dummy function</p> Source code in <code>src/basis_pursuit/basis_pursuit_experiment.py</code> <pre><code>def run_basis_pursuit_experiment() -&gt; None:\n    \"\"\"Dummy function\"\"\"\n    viol = np.zeros((4, seeds, iters))\n    obj = np.zeros((4, seeds, iters))\n    res = np.zeros((4, seeds, iters))\n    times = np.zeros((4, seeds))\n\n    for seed in range(seeds):\n        print(\"seed = \", str(seed + 1), \" of \", seeds)\n        np.random.seed(seed)\n        A = np.random.normal(0, 1.0 / m, size=(m, n))\n        x = np.random.normal(0, 1.0, size=(n, 1)) * np.random.binomial(n=1, p=0.05, size=(n, 1))\n        b = A @ x\n\n        _, viol[0, seed, :], obj[0, seed, :], res[0, seed, :], times[0, seed] = PP(\n            A, b, num_iters=iters\n        )\n        _, viol[1, seed, :], obj[1, seed, :], res[1, seed, :], times[1, seed] = LMM(\n            A, b, num_iters=iters\n        )\n        _, viol[2, seed, :], obj[2, seed, :], res[2, seed, :], times[2, seed] = LB(\n            A, b, num_iters=iters\n        )\n        _, viol[3, seed, :], obj[3, seed, :], res[3, seed, :], times[3, seed] = PDHG(\n            A, b, num_iters=iters\n        )\n\n    viol_pp = np.median(viol[0, :, :], axis=0)\n    viol_lmm = np.median(viol[1, :, :], axis=0)\n    viol_lb = np.median(viol[2, :, :], axis=0)\n    viol_pdhg = np.median(viol[3, :, :], axis=0)\n\n    obj_pp = np.median(obj[0, :, :], axis=0)\n    obj_lmm = np.median(obj[1, :, :], axis=0)\n    obj_lb = np.median(obj[2, :, :], axis=0)\n    obj_pdhg = np.median(obj[3, :, :], axis=0)\n\n    res_pp = np.median(res[0, :, :], axis=0)\n    res_lmm = np.median(res[1, :, :], axis=0)\n    res_lb = np.median(res[2, :, :], axis=0)\n    res_pdhg = np.median(res[3, :, :], axis=0)\n\n    times_pp = np.mean(times[0, :])\n    times_lmm = np.mean(times[1, :])\n    times_lb = np.mean(times[2, :])\n    times_pdhg = np.mean(times[3, :])\n\n    print(\"PP   median time = %0.2f s\" % times_pp)\n    print(\"LMM  median time = %0.2f s\" % times_lmm)\n    print(\"LB   median time = %0.2f s\" % times_lb)\n    print(\"PDHG median time = %0.2f s\" % times_pdhg)\n</code></pre> <p></p>"},{"location":"notebooks/basis_pursuit/","title":"Basis Pursuit","text":"In\u00a0[7]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nimport time\n\nm = 1250\nn = 5000\niters = 2000\nseeds = 20\n\n\ndef shrink(xi, alpha):\n    \"\"\"Execute element-wise soft-threshold\"\"\"\n    return np.sign(xi) * np.maximum(np.abs(xi) - alpha, 0)\n\n\ndef update_stats(x, x_p, viol, obj, res, k):\n    \"\"\"Update arrays that store performance statistics.\"\"\"\n    viol[k] = np.linalg.norm(A @ x - b)\n    obj[k] = np.linalg.norm(x, ord=1)\n    res[k] = np.linalg.norm(x - x_p)\n    return viol, obj, res\n</pre> import numpy as np import matplotlib.pyplot as plt import time  m = 1250 n = 5000 iters = 2000 seeds = 20   def shrink(xi, alpha):     \"\"\"Execute element-wise soft-threshold\"\"\"     return np.sign(xi) * np.maximum(np.abs(xi) - alpha, 0)   def update_stats(x, x_p, viol, obj, res, k):     \"\"\"Update arrays that store performance statistics.\"\"\"     viol[k] = np.linalg.norm(A @ x - b)     obj[k] = np.linalg.norm(x, ord=1)     res[k] = np.linalg.norm(x - x_p)     return viol, obj, res In\u00a0[8]: Copied! <pre>def PP(A, b, alpha=1.0e-1, num_iters=2000):\n    \"\"\"Execute proximal projection algorithm\"\"\"\n    viol = np.zeros(num_iters)\n    obj = np.zeros(num_iters)\n    res = np.zeros(num_iters)\n    z = np.zeros((n, 1))\n    x = np.zeros((n, 1))\n    start = time.time()\n    AAt = np.linalg.inv(A @ A.T)\n    for k in range(num_iters):\n        x_p = x.copy()\n        x = z - A.T @ (AAt @ (A @ z - b))\n        z = z + shrink(2.0 * x - z, alpha) - x\n        viol, obj, res = update_stats(x, x_p, viol, obj, res, k)\n    stop = time.time()\n    return x, viol, obj, res, (stop - start)\n\n\ndef LB(A, b, mu=2.0, num_iters=2000):\n    \"\"\"Execute linearized bregman algorithm\n\n    Note: This solves the problem\n           min  mu * ||x||_1 + ||x||_2^2 / 2 * alpha,\n            x\n\n          subject to the linear constraint A @ x = b.\n          So, mu must be chosen \"large enough\" to ensure\n          the minimizer of the L1 norm is obtained.\n    \"\"\"\n    viol = np.zeros(num_iters)\n    obj = np.zeros(num_iters)\n    res = np.zeros(num_iters)\n    x = np.zeros((n, 1))\n    v = np.zeros((n, 1))\n    start = time.time()\n    A_norm = np.linalg.norm(A @ A.T)\n    alpha = 2.0 / A_norm\n    mu *= A_norm\n    for k in range(num_iters):\n        x_p = x.copy()\n        v = v - A.T @ (A @ x - b)\n        x = shrink(alpha * v, alpha * mu)\n        viol, obj, res = update_stats(x, x_p, viol, obj, res, k)\n    stop = time.time()\n    return x, viol, obj, res, (stop - start)\n\n\ndef LMM(A, b, lambd=100.0, num_iters=2000):\n    \"\"\"Execute linearized method of multipliers algorithm\"\"\"\n    viol = np.zeros(num_iters)\n    obj = np.zeros(num_iters)\n    res = np.zeros(num_iters)\n    x = np.zeros((n, 1))\n    v = np.zeros((m, 1))\n    start = time.time()\n    lambd *= np.linalg.norm(A.T @ A)\n    alpha = 1.0 / (lambd * np.linalg.norm(A.T @ A))\n    for k in range(num_iters):\n        x_p = x.copy()\n        x = shrink(x - alpha * A.T @ (v + lambd * (A @ x - b)), alpha)\n        v = v + lambd * (A @ x - b)\n        viol, obj, res = update_stats(x, x_p, viol, obj, res, k)\n    stop = time.time()\n    return x, viol, obj, res, (stop - start)\n\n\ndef PDHG(A, b, lambd=100.0, num_iters=2000):\n    \"\"\"Execute primal dual hybrid gradient algorithm\"\"\"\n    viol = np.zeros(num_iters)\n    obj = np.zeros(num_iters)\n    res = np.zeros(num_iters)\n    x = np.zeros((n, 1))\n    v = np.zeros((m, 1))\n    alpha = 1.0 / (lambd * np.linalg.norm(A.T @ A))\n    start = time.time()\n    for k in range(num_iters):\n        x_p = x.copy()\n        x = shrink(x - alpha * A.T @ v, alpha)\n        v = v + lambd * (A @ (2 * x - x_p) - b)\n        viol, obj, res = update_stats(x, x_p, viol, obj, res, k)\n    stop = time.time()\n    return x, viol, obj, res, (stop - start)\n</pre> def PP(A, b, alpha=1.0e-1, num_iters=2000):     \"\"\"Execute proximal projection algorithm\"\"\"     viol = np.zeros(num_iters)     obj = np.zeros(num_iters)     res = np.zeros(num_iters)     z = np.zeros((n, 1))     x = np.zeros((n, 1))     start = time.time()     AAt = np.linalg.inv(A @ A.T)     for k in range(num_iters):         x_p = x.copy()         x = z - A.T @ (AAt @ (A @ z - b))         z = z + shrink(2.0 * x - z, alpha) - x         viol, obj, res = update_stats(x, x_p, viol, obj, res, k)     stop = time.time()     return x, viol, obj, res, (stop - start)   def LB(A, b, mu=2.0, num_iters=2000):     \"\"\"Execute linearized bregman algorithm      Note: This solves the problem            min  mu * ||x||_1 + ||x||_2^2 / 2 * alpha,             x            subject to the linear constraint A @ x = b.           So, mu must be chosen \"large enough\" to ensure           the minimizer of the L1 norm is obtained.     \"\"\"     viol = np.zeros(num_iters)     obj = np.zeros(num_iters)     res = np.zeros(num_iters)     x = np.zeros((n, 1))     v = np.zeros((n, 1))     start = time.time()     A_norm = np.linalg.norm(A @ A.T)     alpha = 2.0 / A_norm     mu *= A_norm     for k in range(num_iters):         x_p = x.copy()         v = v - A.T @ (A @ x - b)         x = shrink(alpha * v, alpha * mu)         viol, obj, res = update_stats(x, x_p, viol, obj, res, k)     stop = time.time()     return x, viol, obj, res, (stop - start)   def LMM(A, b, lambd=100.0, num_iters=2000):     \"\"\"Execute linearized method of multipliers algorithm\"\"\"     viol = np.zeros(num_iters)     obj = np.zeros(num_iters)     res = np.zeros(num_iters)     x = np.zeros((n, 1))     v = np.zeros((m, 1))     start = time.time()     lambd *= np.linalg.norm(A.T @ A)     alpha = 1.0 / (lambd * np.linalg.norm(A.T @ A))     for k in range(num_iters):         x_p = x.copy()         x = shrink(x - alpha * A.T @ (v + lambd * (A @ x - b)), alpha)         v = v + lambd * (A @ x - b)         viol, obj, res = update_stats(x, x_p, viol, obj, res, k)     stop = time.time()     return x, viol, obj, res, (stop - start)   def PDHG(A, b, lambd=100.0, num_iters=2000):     \"\"\"Execute primal dual hybrid gradient algorithm\"\"\"     viol = np.zeros(num_iters)     obj = np.zeros(num_iters)     res = np.zeros(num_iters)     x = np.zeros((n, 1))     v = np.zeros((m, 1))     alpha = 1.0 / (lambd * np.linalg.norm(A.T @ A))     start = time.time()     for k in range(num_iters):         x_p = x.copy()         x = shrink(x - alpha * A.T @ v, alpha)         v = v + lambd * (A @ (2 * x - x_p) - b)         viol, obj, res = update_stats(x, x_p, viol, obj, res, k)     stop = time.time()     return x, viol, obj, res, (stop - start) In\u00a0[9]: Copied! <pre>viol = np.zeros((4, seeds, iters))\nobj = np.zeros((4, seeds, iters))\nres = np.zeros((4, seeds, iters))\ntimes = np.zeros((4, seeds))\n\nfor seed in range(seeds):\n    print(\"seed = \", str(seed + 1), \" of \", seeds)\n    np.random.seed(seed)\n    A = np.random.normal(0, 1.0 / m, size=(m, n))\n    x = np.random.normal(0, 1.0, size=(n, 1)) * np.random.binomial(n=1, p=0.05, size=(n, 1))\n    b = A @ x\n\n    _, viol[0, seed, :], obj[0, seed, :], res[0, seed, :], times[0, seed] = PP(\n        A, b, num_iters=iters\n    )\n    _, viol[1, seed, :], obj[1, seed, :], res[1, seed, :], times[1, seed] = LMM(\n        A, b, num_iters=iters\n    )\n    _, viol[2, seed, :], obj[2, seed, :], res[2, seed, :], times[2, seed] = LB(\n        A, b, num_iters=iters\n    )\n    _, viol[3, seed, :], obj[3, seed, :], res[3, seed, :], times[3, seed] = PDHG(\n        A, b, num_iters=iters\n    )\n\nviol_pp = np.median(viol[0, :, :], axis=0)\nviol_lmm = np.median(viol[1, :, :], axis=0)\nviol_lb = np.median(viol[2, :, :], axis=0)\nviol_pdhg = np.median(viol[3, :, :], axis=0)\n\nobj_pp = np.median(obj[0, :, :], axis=0)\nobj_lmm = np.median(obj[1, :, :], axis=0)\nobj_lb = np.median(obj[2, :, :], axis=0)\nobj_pdhg = np.median(obj[3, :, :], axis=0)\n\nres_pp = np.median(res[0, :, :], axis=0)\nres_lmm = np.median(res[1, :, :], axis=0)\nres_lb = np.median(res[2, :, :], axis=0)\nres_pdhg = np.median(res[3, :, :], axis=0)\n\ntimes_pp = np.mean(times[0, :])\ntimes_lmm = np.mean(times[1, :])\ntimes_lb = np.mean(times[2, :])\ntimes_pdhg = np.mean(times[3, :])\n\nprint(\"PP   median time = %0.2f s\" % times_pp)\nprint(\"LMM  median time = %0.2f s\" % times_lmm)\nprint(\"LB   median time = %0.2f s\" % times_lb)\nprint(\"PDHG median time = %0.2f s\" % times_pdhg)\n</pre> viol = np.zeros((4, seeds, iters)) obj = np.zeros((4, seeds, iters)) res = np.zeros((4, seeds, iters)) times = np.zeros((4, seeds))  for seed in range(seeds):     print(\"seed = \", str(seed + 1), \" of \", seeds)     np.random.seed(seed)     A = np.random.normal(0, 1.0 / m, size=(m, n))     x = np.random.normal(0, 1.0, size=(n, 1)) * np.random.binomial(n=1, p=0.05, size=(n, 1))     b = A @ x      _, viol[0, seed, :], obj[0, seed, :], res[0, seed, :], times[0, seed] = PP(         A, b, num_iters=iters     )     _, viol[1, seed, :], obj[1, seed, :], res[1, seed, :], times[1, seed] = LMM(         A, b, num_iters=iters     )     _, viol[2, seed, :], obj[2, seed, :], res[2, seed, :], times[2, seed] = LB(         A, b, num_iters=iters     )     _, viol[3, seed, :], obj[3, seed, :], res[3, seed, :], times[3, seed] = PDHG(         A, b, num_iters=iters     )  viol_pp = np.median(viol[0, :, :], axis=0) viol_lmm = np.median(viol[1, :, :], axis=0) viol_lb = np.median(viol[2, :, :], axis=0) viol_pdhg = np.median(viol[3, :, :], axis=0)  obj_pp = np.median(obj[0, :, :], axis=0) obj_lmm = np.median(obj[1, :, :], axis=0) obj_lb = np.median(obj[2, :, :], axis=0) obj_pdhg = np.median(obj[3, :, :], axis=0)  res_pp = np.median(res[0, :, :], axis=0) res_lmm = np.median(res[1, :, :], axis=0) res_lb = np.median(res[2, :, :], axis=0) res_pdhg = np.median(res[3, :, :], axis=0)  times_pp = np.mean(times[0, :]) times_lmm = np.mean(times[1, :]) times_lb = np.mean(times[2, :]) times_pdhg = np.mean(times[3, :])  print(\"PP   median time = %0.2f s\" % times_pp) print(\"LMM  median time = %0.2f s\" % times_lmm) print(\"LB   median time = %0.2f s\" % times_lb) print(\"PDHG median time = %0.2f s\" % times_pdhg) <pre>seed =  1  of  20\nseed =  2  of  20\nseed =  3  of  20\nseed =  4  of  20\nseed =  5  of  20\nseed =  6  of  20\nseed =  7  of  20\nseed =  8  of  20\nseed =  9  of  20\nseed =  10  of  20\nseed =  11  of  20\nseed =  12  of  20\nseed =  13  of  20\nseed =  14  of  20\nseed =  15  of  20\nseed =  16  of  20\nseed =  17  of  20\nseed =  18  of  20\nseed =  19  of  20\nseed =  20  of  20\nPP   median time = 8.06 s\nLMM  median time = 22.85 s\nLB   median time = 7.40 s\nPDHG median time = 20.60 s\n</pre> In\u00a0[10]: Copied! <pre>fig, ax = plt.subplots()\nplt.title(\"Violation $|Ax-b|$\")\nplt.plot(viol_pp, color=\"b\")\nplt.plot(viol_lb, color=\"g\")\nplt.plot(viol_lmm, color=\"k\")\nplt.plot(viol_pdhg, color=\"r\")\nplt.yscale(\"log\")\nplt.show()\n\nfig, ax = plt.subplots()\nplt.title(\"Objective |x^k|_1\")\nplt.plot(obj_pp, color=\"b\")\nplt.plot(obj_lb, color=\"g\")\nplt.plot(obj_lmm, color=\"k\")\nplt.plot(obj_pdhg, color=\"r\")\nplt.show()\n\nfig, ax = plt.subplots()\nplt.title(\"Residual $|x^{k+1}-x^k|$\")\nplt.plot(res_pp, color=\"b\")\nplt.plot(res_lb, color=\"g\")\nplt.plot(res_lmm, color=\"k\")\nplt.plot(res_pdhg, color=\"r\")\nplt.yscale(\"log\")\nplt.show()\n</pre> fig, ax = plt.subplots() plt.title(\"Violation $|Ax-b|$\") plt.plot(viol_pp, color=\"b\") plt.plot(viol_lb, color=\"g\") plt.plot(viol_lmm, color=\"k\") plt.plot(viol_pdhg, color=\"r\") plt.yscale(\"log\") plt.show()  fig, ax = plt.subplots() plt.title(\"Objective |x^k|_1\") plt.plot(obj_pp, color=\"b\") plt.plot(obj_lb, color=\"g\") plt.plot(obj_lmm, color=\"k\") plt.plot(obj_pdhg, color=\"r\") plt.show()  fig, ax = plt.subplots() plt.title(\"Residual $|x^{k+1}-x^k|$\") plt.plot(res_pp, color=\"b\") plt.plot(res_lb, color=\"g\") plt.plot(res_lmm, color=\"k\") plt.plot(res_pdhg, color=\"r\") plt.yscale(\"log\") plt.show() In\u00a0[11]: Copied! <pre>filename = \"../results/bp-obj-plots.csv\"\nwith open(filename, \"w\") as csv_file:\n    for k in range(iters):\n        if k % 1 == 0:\n            csv_file.write(\n                \"%0.5e,%0.5e,%0.5e,%0.5e\\n\" % (obj_pp[k], obj_lmm[k], obj_lb[k], obj_pdhg[k])\n            )\nfilename = \"../results/bp-viol-plots.csv\"\nwith open(filename, \"w\") as csv_file:\n    for k in range(iters):\n        if k % 1 == 0:\n            csv_file.write(\n                \"%0.5e,%0.5e,%0.5e,%0.5e\\n\" % (viol_pp[k], viol_lmm[k], viol_lb[k], viol_pdhg[k])\n            )\nfilename = \"../results/bp-res-plots.csv\"\nwith open(filename, \"w\") as csv_file:\n    for k in range(iters):\n        if k % 1 == 0:\n            csv_file.write(\n                \"%0.5e,%0.5e,%0.5e,%0.5e\\n\" % (res_pp[k], res_lmm[k], res_lb[k], res_pdhg[k])\n            )\nfilename = \"../results/bp-times.tex\"\nwith open(filename, \"w\") as csv_file:\n    csv_file.write(\"\\\\def\\\\bpTimePP{%0.2f}\\n\" % (times_pp))\n    csv_file.write(\"\\\\def\\\\bpTimeLB{%0.2f}\\n\" % (times_lb))\n    csv_file.write(\"\\\\def\\\\bpTimePDHG{%0.2f}\\n\" % (times_pdhg))\n    csv_file.write(\"\\\\def\\\\bpTimeLMM{%0.2f}\" % (times_lmm))\n</pre> filename = \"../results/bp-obj-plots.csv\" with open(filename, \"w\") as csv_file:     for k in range(iters):         if k % 1 == 0:             csv_file.write(                 \"%0.5e,%0.5e,%0.5e,%0.5e\\n\" % (obj_pp[k], obj_lmm[k], obj_lb[k], obj_pdhg[k])             ) filename = \"../results/bp-viol-plots.csv\" with open(filename, \"w\") as csv_file:     for k in range(iters):         if k % 1 == 0:             csv_file.write(                 \"%0.5e,%0.5e,%0.5e,%0.5e\\n\" % (viol_pp[k], viol_lmm[k], viol_lb[k], viol_pdhg[k])             ) filename = \"../results/bp-res-plots.csv\" with open(filename, \"w\") as csv_file:     for k in range(iters):         if k % 1 == 0:             csv_file.write(                 \"%0.5e,%0.5e,%0.5e,%0.5e\\n\" % (res_pp[k], res_lmm[k], res_lb[k], res_pdhg[k])             ) filename = \"../results/bp-times.tex\" with open(filename, \"w\") as csv_file:     csv_file.write(\"\\\\def\\\\bpTimePP{%0.2f}\\n\" % (times_pp))     csv_file.write(\"\\\\def\\\\bpTimeLB{%0.2f}\\n\" % (times_lb))     csv_file.write(\"\\\\def\\\\bpTimePDHG{%0.2f}\\n\" % (times_pdhg))     csv_file.write(\"\\\\def\\\\bpTimeLMM{%0.2f}\" % (times_lmm)) In\u00a0[12]: Copied! <pre>import cvxpy as cp\n\nx = cp.Variable((n, 1))\nobjective = cp.Minimize(cp.sum(cp.abs(x)))\nconstraints = [A @ x == b]\nprob = cp.Problem(objective, constraints)\nresult = prob.solve(verbose=True)\n\nprint(\"|x| = \", np.sum(np.abs(x.value)))\nprint(\"|Ax - b| = \", np.sum(np.abs(A @ x.value - b)))\n</pre> import cvxpy as cp  x = cp.Variable((n, 1)) objective = cp.Minimize(cp.sum(cp.abs(x))) constraints = [A @ x == b] prob = cp.Problem(objective, constraints) result = prob.solve(verbose=True)  print(\"|x| = \", np.sum(np.abs(x.value))) print(\"|Ax - b| = \", np.sum(np.abs(A @ x.value - b))) <pre>===============================================================================\n                                     CVXPY                                     \n                                     v1.5.2                                    \n===============================================================================\n(CVXPY) Jul 23 05:36:56 PM: Your problem has 5000 variables, 1250 constraints, and 0 parameters.\n(CVXPY) Jul 23 05:36:56 PM: It is compliant with the following grammars: DCP, DQCP\n(CVXPY) Jul 23 05:36:56 PM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n(CVXPY) Jul 23 05:36:56 PM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n(CVXPY) Jul 23 05:36:56 PM: Your problem is compiled with the CPP canonicalization backend.\n-------------------------------------------------------------------------------\n                                  Compilation                                  \n-------------------------------------------------------------------------------\n(CVXPY) Jul 23 05:36:56 PM: Compiling problem (target solver=CLARABEL).\n(CVXPY) Jul 23 05:36:56 PM: Reduction chain: Dcp2Cone -&gt; CvxAttr2Constr -&gt; ConeMatrixStuffing -&gt; CLARABEL\n(CVXPY) Jul 23 05:36:56 PM: Applying reduction Dcp2Cone\n(CVXPY) Jul 23 05:36:56 PM: Applying reduction CvxAttr2Constr\n(CVXPY) Jul 23 05:36:56 PM: Applying reduction ConeMatrixStuffing\n(CVXPY) Jul 23 05:36:57 PM: Applying reduction CLARABEL\n(CVXPY) Jul 23 05:36:57 PM: Finished problem compilation (took 1.518e+00 seconds).\n-------------------------------------------------------------------------------\n                                Numerical solver                               \n-------------------------------------------------------------------------------\n(CVXPY) Jul 23 05:36:57 PM: Invoking solver CLARABEL  to obtain a solution.\n-------------------------------------------------------------\n           Clarabel.rs v0.9.0  -  Clever Acronym                \n\n                   (c) Paul Goulart                          \n                University of Oxford, 2022                   \n-------------------------------------------------------------\n\nproblem:\n  variables     = 10000\n  constraints   = 11250\n  nnz(P)        = 0\n  nnz(A)        = 6270000\n  cones (total) = 2\n    :        Zero = 1,  numel = 1250\n    : Nonnegative = 1,  numel = 10000\n\nsettings:\n  linear algebra: direct / qdldl, precision: 64 bit\n  max iter = 200, time limit = Inf,  max step = 0.990\n  tol_feas = 1.0e-8, tol_gap_abs = 1.0e-8, tol_gap_rel = 1.0e-8,\n  static reg : on, \u03f51 = 1.0e-8, \u03f52 = 4.9e-32\n  dynamic reg: on, \u03f5 = 1.0e-13, \u03b4 = 2.0e-7\n  iter refine: on, reltol = 1.0e-13, abstol = 1.0e-12,\n               max iter = 10, stop ratio = 5.0\n  equilibrate: on, min_scale = 1.0e-4, max_scale = 1.0e4\n               max iter = 10\n\niter    pcost        dcost       gap       pres      dres      k/t        \u03bc       step      \n---------------------------------------------------------------------------------------------\n  0  +1.4716e-23  -7.3128e-17  7.31e-17  9.57e-01  6.50e-01  1.00e+00  1.80e+00   ------   \n  1  +8.8651e+01  +8.8760e+01  1.22e-03  7.21e-01  1.76e-01  2.78e-01  5.19e-01  8.12e-01  \n  2  +1.5012e+02  +1.5018e+02  4.20e-04  4.86e-01  1.08e-01  1.71e-01  3.46e-01  5.20e-01  \n  3  +1.7209e+02  +1.7213e+02  2.08e-04  2.91e-01  6.41e-02  1.01e-01  2.17e-01  4.47e-01  \n  4  +1.8641e+02  +1.8643e+02  8.64e-05  1.51e-01  3.47e-02  5.24e-02  1.24e-01  5.62e-01  \n  5  +1.9359e+02  +1.9359e+02  3.37e-05  8.59e-02  2.05e-02  2.85e-02  7.58e-02  5.93e-01  \n  6  +1.9651e+02  +1.9651e+02  1.39e-05  5.24e-02  1.29e-02  1.68e-02  4.89e-02  5.56e-01  \n  7  +1.9878e+02  +1.9878e+02  3.65e-06  2.90e-02  7.33e-03  8.78e-03  2.82e-02  6.71e-01  \n  8  +1.9978e+02  +1.9978e+02  1.24e-06  1.86e-02  4.79e-03  5.55e-03  1.86e-02  5.27e-01  \n  9  +2.0050e+02  +2.0050e+02  9.32e-08  1.09e-02  2.84e-03  3.14e-03  1.11e-02  6.77e-01  \n 10  +2.0080e+02  +2.0080e+02  2.69e-07  7.58e-03  1.98e-03  2.16e-03  7.82e-03  4.94e-01  \n 11  +2.0103e+02  +2.0103e+02  4.24e-07  5.14e-03  1.35e-03  1.43e-03  5.35e-03  7.58e-01  \n 12  +2.0121e+02  +2.0121e+02  2.81e-07  2.54e-03  6.72e-04  7.01e-04  2.67e-03  9.90e-01  \n 13  +2.0125e+02  +2.0125e+02  1.65e-07  1.45e-03  3.86e-04  4.02e-04  1.54e-03  9.90e-01  \n 14  +2.0131e+02  +2.0131e+02  2.77e-08  2.41e-04  6.43e-05  6.72e-05  2.57e-04  9.01e-01  \n 15  +2.0132e+02  +2.0132e+02  1.21e-08  1.04e-04  2.77e-05  2.90e-05  1.11e-04  9.90e-01  \n 16  +2.0132e+02  +2.0132e+02  7.32e-10  6.30e-06  1.68e-06  1.76e-06  6.72e-06  9.42e-01  \n 17  +2.0132e+02  +2.0132e+02  7.33e-12  6.30e-08  1.68e-08  1.76e-08  6.72e-08  9.90e-01  \n 18  +2.0132e+02  +2.0132e+02  6.88e-14  6.41e-10  1.71e-10  1.79e-10  6.83e-10  9.90e-01  \n---------------------------------------------------------------------------------------------\nTerminated with status = Solved\nsolve time = 86.646018501s\n-------------------------------------------------------------------------------\n                                    Summary                                    \n-------------------------------------------------------------------------------\n(CVXPY) Jul 23 05:38:25 PM: Problem status: optimal\n(CVXPY) Jul 23 05:38:25 PM: Optimal value: 2.013e+02\n(CVXPY) Jul 23 05:38:25 PM: Compilation took 1.518e+00 seconds\n(CVXPY) Jul 23 05:38:25 PM: Solver (including time spent in interface) took 8.732e+01 seconds\n|x| =  201.3212978720586\n|Ax - b| =  1.1977110861254026e-10\n</pre>"},{"location":"notebooks/basis_pursuit/#basis-pursuit","title":"Basis Pursuit\u00b6","text":"<p>This notebook serves to benchmark proximal projection (PP) against existing alternatives on an instance the basis pursuit problem</p> <p>$$ \\min_{x\\in\\mathbb{R}^n} \\|x\\|_1 \\ \\ \\mbox{s.t.}\\ \\ Ax = b.$$</p> <p>The first cell imports the needed libraries and defines the experiment setup: $m = 1250$ and $n=5000$ along with a function for logging perfomance of each algorithm.</p>"},{"location":"notebooks/basis_pursuit/#define-algorithms","title":"Define Algorithms\u00b6","text":"<p>As defined in Appendix B.1 of the paper, here we implement the following:</p> <ul> <li>Proximal Projection (PP)</li> <li>Linearized Bregman (LB)</li> <li>Linearized Method of Multipliers (LMM)</li> <li>Primal Dual Hybrid Gradient (PDHG)</li> </ul>"},{"location":"notebooks/basis_pursuit/#benchmark-algorithms","title":"Benchmark Algorithms\u00b6","text":"<p>We repeat 20 trials with different random seeds and report the median execution time of each algorithm.</p>"},{"location":"notebooks/basis_pursuit/#plot-median-convergence-results","title":"Plot Median Convergence Results\u00b6","text":""},{"location":"notebooks/basis_pursuit/#save-plots-and-times","title":"Save Plots and Times\u00b6","text":""},{"location":"notebooks/basis_pursuit/#cvx-comparison","title":"CVX Comparison\u00b6","text":"<p>As a sanity check, we include a CVX implementation to compute the solution to the basis pursuit problem using the final seed from the above setup.</p>"},{"location":"notebooks/earth_movers_distance/","title":"Earth Mover's Distance","text":"In\u00a0[82]: Copied! <pre>import numpy as np\nimport scipy as sp\nfrom scipy.linalg import solveh_banded\nfrom scipy.sparse import diags\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n</pre> import numpy as np import scipy as sp from scipy.linalg import solveh_banded from scipy.sparse import diags import matplotlib.pyplot as plt from PIL import Image In\u00a0[83]: Copied! <pre>def get_distributions(file0, file1, directory=\"../data/\"):\n    \"\"\"Generate densities for EMD calculation\n\n    The images are imported as grayscale. The\n    values are then flipped so that the cats,\n    originally shown in black, are shown in white\n    and the background is black. Then the mass of\n    each cat is normalized.\n    \"\"\"\n    img0 = Image.open(directory + file0).convert(\"L\")\n    img1 = Image.open(directory + file1).convert(\"L\")\n\n    rho0 = np.asarray(img0)\n    rho0 = 255.0 * np.ones(rho0.shape) - rho0\n    rho0 /= np.sum(rho0)\n\n    rho1 = np.asarray(img1)\n    rho1 = 255.0 * np.ones(rho1.shape) - rho1\n    rho1 /= np.sum(rho1)\n\n    rho0_has_unit_density = np.isclose(np.sum(rho0), 1)\n    rho1_has_unit_density = np.isclose(np.sum(rho1), 1)\n    assert rho0_has_unit_density\n    assert rho1_has_unit_density\n\n    rho0_is_square = rho0.shape[0] == rho0.shape[1]\n    rho1_is_square = rho1.shape[0] == rho1.shape[1]\n    assert rho0_is_square\n    assert rho1_is_square\n\n    rho0_rho1_are_same_size = rho0.shape[0] == rho1.shape[0]\n    assert rho0_rho1_are_same_size\n\n    n = rho0.shape[0]\n    return rho0, rho1\n\n\ndef shrink(x, alpha):\n    \"\"\"Perform soft thresholding for either L1 or L2 norm.\"\"\"\n    return np.sign(x) * np.maximum(np.abs(x) - alpha, 0)\n\n\ndef construct_K(n):\n    \"\"\"Construct a finite differencing matrix K and [K K.T] * [K.T; K].\n\n    The matrix A takes the form [K K^T], where K is a backward discrete\n    differencing operator. The product A * A^T = K * K^T + K^T * K is a\n    triagonal matrix, which is used in constructing the Q matrix of the\n    Proximal Nullspace Solver.\n    \"\"\"\n    K_full = np.eye(n, n - 1)\n    K_full[1:, :] += -np.eye(n - 1)\n    K = sp.sparse.csr_matrix(K_full)\n    return K\n\n\ndef apply_div(z):\n    \"\"\"Compute the divergence of provide flux.\n\n    Here the matrix K is a discrete differencing operator.\n    \"\"\"\n    n = int(z.shape[0] / 2 + 1)\n    flux_shape_is_valid = n == z.shape[1]\n    assert flux_shape_is_valid\n\n    K = construct_K(n)\n    div = K @ z[: (n - 1), :] + (K @ z[(n - 1) :, :]).T\n    return div\n</pre> def get_distributions(file0, file1, directory=\"../data/\"):     \"\"\"Generate densities for EMD calculation      The images are imported as grayscale. The     values are then flipped so that the cats,     originally shown in black, are shown in white     and the background is black. Then the mass of     each cat is normalized.     \"\"\"     img0 = Image.open(directory + file0).convert(\"L\")     img1 = Image.open(directory + file1).convert(\"L\")      rho0 = np.asarray(img0)     rho0 = 255.0 * np.ones(rho0.shape) - rho0     rho0 /= np.sum(rho0)      rho1 = np.asarray(img1)     rho1 = 255.0 * np.ones(rho1.shape) - rho1     rho1 /= np.sum(rho1)      rho0_has_unit_density = np.isclose(np.sum(rho0), 1)     rho1_has_unit_density = np.isclose(np.sum(rho1), 1)     assert rho0_has_unit_density     assert rho1_has_unit_density      rho0_is_square = rho0.shape[0] == rho0.shape[1]     rho1_is_square = rho1.shape[0] == rho1.shape[1]     assert rho0_is_square     assert rho1_is_square      rho0_rho1_are_same_size = rho0.shape[0] == rho1.shape[0]     assert rho0_rho1_are_same_size      n = rho0.shape[0]     return rho0, rho1   def shrink(x, alpha):     \"\"\"Perform soft thresholding for either L1 or L2 norm.\"\"\"     return np.sign(x) * np.maximum(np.abs(x) - alpha, 0)   def construct_K(n):     \"\"\"Construct a finite differencing matrix K and [K K.T] * [K.T; K].      The matrix A takes the form [K K^T], where K is a backward discrete     differencing operator. The product A * A^T = K * K^T + K^T * K is a     triagonal matrix, which is used in constructing the Q matrix of the     Proximal Nullspace Solver.     \"\"\"     K_full = np.eye(n, n - 1)     K_full[1:, :] += -np.eye(n - 1)     K = sp.sparse.csr_matrix(K_full)     return K   def apply_div(z):     \"\"\"Compute the divergence of provide flux.      Here the matrix K is a discrete differencing operator.     \"\"\"     n = int(z.shape[0] / 2 + 1)     flux_shape_is_valid = n == z.shape[1]     assert flux_shape_is_valid      K = construct_K(n)     div = K @ z[: (n - 1), :] + (K @ z[(n - 1) :, :]).T     return div In\u00a0[84]: Copied! <pre>def update_stats(m, m_p, viol, obj, res, k, verbose=False):\n    \"\"\"Update arrays that store performance statistics.\"\"\"\n    viol[k] = np.linalg.norm(apply_div(m) + rho1 - rho0)\n    obj[k] = np.sum(np.abs(m))\n    res[k] = np.linalg.norm(m - m_p, ord=\"fro\")\n\n    if k % 100 == 0 and verbose:\n        print(\n            \"[{:5d}]: |m - m_p| = {:0.3e}, |Am - b| = {:0.3e} obj = {:0.5e}\".format(\n                k, res[k], viol[k], obj[k]\n            )\n        )\n\n    return viol, obj, res\n\n\ndef PDHG(rho0, rho1, num_iters=500, verbose=False):\n    \"\"\"Apply Proximal Dual Hybrid Gradient to compute Earth Mover's Distance\n\n    Convergence is ensured when mu * tau * lambd_max(div), where div is\n    the matrix for the divergence operator.\n\n    m = [mx; my^T]\n\n    Boundary conditions are held by simply removing those \"ghost entries\"\n    mx[-1, :]   = 0\n    my^T[-1, :] = 0\n    # m = [mx; my.T], x for i, y for j\n    \"\"\"\n    viol = np.zeros(num_iters)\n    obj = np.zeros(num_iters)\n    res = np.zeros(num_iters)\n    n = rho0.shape[0]\n    m = np.zeros((2 * (n - 1), n))\n    phi = np.zeros((n, n))\n    tau = 1.0e4\n    K = construct_K(n)\n    L = 2.0 * np.linalg.norm(K.toarray().T @ K.toarray(), ord=2)\n    mu = 1.0 / (tau * L)\n\n    for k in range(num_iters):\n        m_p = m.copy()\n        Dphi = np.concatenate((K.T @ phi, (K.T @ phi.T)), axis=0)\n        m = shrink(m - mu * Dphi, mu)\n        div = apply_div(2.0 * m - m_p)\n        phi = phi + tau * (div + rho1 - rho0)\n\n        viol, obj, res = update_stats(m, m_p, viol, obj, res, k, verbose=verbose)\n\n    return m, viol, obj, res\n\n\ndef GPDHG(rho0, rho1, num_iters=1000, eps=1.0e-10, verbose=False):\n    \"\"\"Apply G Prox PDHG\"\"\"\n    viol = np.zeros(num_iters)\n    obj = np.zeros(num_iters)\n    res = np.zeros(num_iters)\n    n = rho0.shape[0]\n    u = np.zeros((2 * (n - 1), n))\n    p = np.zeros((2 * (n - 1), n))\n\n    K = construct_K(n)\n\n    tau = 1.0e-4\n    sigma = 1.0 / tau\n\n    \"\"\" Get SVD \"\"\"\n    U, S, Vt = np.linalg.svd(K.toarray(), full_matrices=True)\n    S = np.concatenate((S, np.zeros(n - S.shape[0])), axis=0)\n    R = np.zeros(U.shape)\n\n    for i in range(n):\n        for j in range(n):\n            R[i, j] += S[i] ** 2.0 + S[j] ** 2.0\n\n    err = rho1 - rho0\n    err_norm = np.linalg.norm(err, ord=\"fro\")\n    t_hi = ((2.0 * S[0]) ** 2.0) / (err_norm - eps)\n    psi = proj(np.zeros(u.shape), err, U, R, K, n, eps, t_hi=t_hi)\n\n    for k in range(num_iters):\n        p_p = p.copy()\n        u_p = u.copy()\n\n        p_t = p + sigma * (u + psi)\n        den = np.maximum(np.ones(p.shape), np.abs(p_t))\n        num = p_t\n\n        assert den.shape == num.shape\n\n        p = num / den\n\n        p_norm = np.max(np.abs(p))\n        assert p_norm &lt;= 1.0, \"wrong p projection: \" + str(p_norm)\n\n        err = apply_div(2 * p - p_p)\n        err_norm = np.linalg.norm(err, ord=\"fro\")\n        if err_norm &gt; eps:\n            t_hi = ((2.0 * S[0]) ** 2.0) / (err_norm - eps)\n            u = u - tau * proj(2 * p - p_p, err, U, R, K, n, eps, t_hi=t_hi)\n        else:\n            u = np.zeros(u.shape)\n\n        m_p = u_p + psi\n        m = u + psi\n        viol, obj, res = update_stats(m, m_p, viol, obj, res, k, verbose=verbose)\n\n    return m, viol, obj, res\n</pre> def update_stats(m, m_p, viol, obj, res, k, verbose=False):     \"\"\"Update arrays that store performance statistics.\"\"\"     viol[k] = np.linalg.norm(apply_div(m) + rho1 - rho0)     obj[k] = np.sum(np.abs(m))     res[k] = np.linalg.norm(m - m_p, ord=\"fro\")      if k % 100 == 0 and verbose:         print(             \"[{:5d}]: |m - m_p| = {:0.3e}, |Am - b| = {:0.3e} obj = {:0.5e}\".format(                 k, res[k], viol[k], obj[k]             )         )      return viol, obj, res   def PDHG(rho0, rho1, num_iters=500, verbose=False):     \"\"\"Apply Proximal Dual Hybrid Gradient to compute Earth Mover's Distance      Convergence is ensured when mu * tau * lambd_max(div), where div is     the matrix for the divergence operator.      m = [mx; my^T]      Boundary conditions are held by simply removing those \"ghost entries\"     mx[-1, :]   = 0     my^T[-1, :] = 0     # m = [mx; my.T], x for i, y for j     \"\"\"     viol = np.zeros(num_iters)     obj = np.zeros(num_iters)     res = np.zeros(num_iters)     n = rho0.shape[0]     m = np.zeros((2 * (n - 1), n))     phi = np.zeros((n, n))     tau = 1.0e4     K = construct_K(n)     L = 2.0 * np.linalg.norm(K.toarray().T @ K.toarray(), ord=2)     mu = 1.0 / (tau * L)      for k in range(num_iters):         m_p = m.copy()         Dphi = np.concatenate((K.T @ phi, (K.T @ phi.T)), axis=0)         m = shrink(m - mu * Dphi, mu)         div = apply_div(2.0 * m - m_p)         phi = phi + tau * (div + rho1 - rho0)          viol, obj, res = update_stats(m, m_p, viol, obj, res, k, verbose=verbose)      return m, viol, obj, res   def GPDHG(rho0, rho1, num_iters=1000, eps=1.0e-10, verbose=False):     \"\"\"Apply G Prox PDHG\"\"\"     viol = np.zeros(num_iters)     obj = np.zeros(num_iters)     res = np.zeros(num_iters)     n = rho0.shape[0]     u = np.zeros((2 * (n - 1), n))     p = np.zeros((2 * (n - 1), n))      K = construct_K(n)      tau = 1.0e-4     sigma = 1.0 / tau      \"\"\" Get SVD \"\"\"     U, S, Vt = np.linalg.svd(K.toarray(), full_matrices=True)     S = np.concatenate((S, np.zeros(n - S.shape[0])), axis=0)     R = np.zeros(U.shape)      for i in range(n):         for j in range(n):             R[i, j] += S[i] ** 2.0 + S[j] ** 2.0      err = rho1 - rho0     err_norm = np.linalg.norm(err, ord=\"fro\")     t_hi = ((2.0 * S[0]) ** 2.0) / (err_norm - eps)     psi = proj(np.zeros(u.shape), err, U, R, K, n, eps, t_hi=t_hi)      for k in range(num_iters):         p_p = p.copy()         u_p = u.copy()          p_t = p + sigma * (u + psi)         den = np.maximum(np.ones(p.shape), np.abs(p_t))         num = p_t          assert den.shape == num.shape          p = num / den          p_norm = np.max(np.abs(p))         assert p_norm &lt;= 1.0, \"wrong p projection: \" + str(p_norm)          err = apply_div(2 * p - p_p)         err_norm = np.linalg.norm(err, ord=\"fro\")         if err_norm &gt; eps:             t_hi = ((2.0 * S[0]) ** 2.0) / (err_norm - eps)             u = u - tau * proj(2 * p - p_p, err, U, R, K, n, eps, t_hi=t_hi)         else:             u = np.zeros(u.shape)          m_p = u_p + psi         m = u + psi         viol, obj, res = update_stats(m, m_p, viol, obj, res, k, verbose=verbose)      return m, viol, obj, res In\u00a0[85]: Copied! <pre>def apply_inv(B, R, U, eps, tau):\n    \"\"\"Apply inverse\"\"\"\n    num = U.T @ B @ U\n    den = R + eps * tau\n    inv = U @ (num / den) @ U.T\n    return inv\n\n\ndef get_tau(B, R, U, eps, t_hi, t_lo=0.0, tol=1.0e-14):\n    \"\"\"bisection method...\"\"\"\n    num = U.T @ B @ U\n    root_est = np.inf\n    while np.abs(root_est) &gt; tol:\n        t = 0.5 * (t_lo + t_hi)\n        den = R + eps * t\n        root_est = t * np.linalg.norm(num / den) - 1.0\n        if root_est &gt; 0.0:\n            t_hi = t\n        else:\n            t_lo = t\n    return t\n\n\ndef proj(X, err, U, R, K, n, eps, t_hi):\n    tau = get_tau(err, R, U, eps, t_hi=t_hi)\n    inv = apply_inv(err, R, U, eps, tau)\n    At_inv = np.concatenate((K.T @ inv, K.T @ inv.T), axis=0)\n    P = X - At_inv\n    return P\n\n\ndef PP(rho0, rho1, alpha=1.0e-4, num_iters=500, eps=1.0e-10, verbose=False):\n    \"\"\"Apply Proximal Dual Hybrid Gradient to compute Earth Mover's Distance\n\n    Convergence is ensured when mu * tau * lambd_max(div), where div is\n    the matrix for the divergence operator.\n\n    m = [mx; my^T]\n\n    Boundary conditions are held by simply removing those \"ghost entries\"\n    mx[-1, :]   = 0\n    my^T[-1, :] = 0\n    \"\"\"\n    viol = np.zeros(num_iters)\n    obj = np.zeros(num_iters)\n    res = np.zeros(num_iters)\n    n = rho0.shape[0]\n    m = np.zeros((2 * (n - 1), n))  # m = [mx; my.T], x for i, y for j\n    z = np.zeros((2 * (n - 1), n))\n    K = construct_K(n)\n\n    \"\"\" Get SVD \"\"\"\n    U, S, Vt = np.linalg.svd(K.toarray(), full_matrices=True)\n    S = np.concatenate((S, np.zeros(n - S.shape[0])), axis=0)\n    R = np.zeros(U.shape)\n\n    for i in range(n):\n        for j in range(n):\n            R[i, j] += S[i] ** 2.0 + S[j] ** 2.0\n\n    for k in range(num_iters):\n        m_p = m.copy()\n\n        err = apply_div(z) + rho1 - rho0\n        err_norm = np.linalg.norm(err, ord=\"fro\")\n        if err_norm &gt; eps:\n            t_hi = ((2.0 * S[0]) ** 2.0) / (err_norm - eps)\n            m = proj(z, err, U, R, K, n, eps, t_hi=t_hi)\n        else:\n            m = z\n        z = z + shrink(2.0 * m - z, alpha) - m\n\n        viol, obj, res = update_stats(m, m_p, viol, obj, res, k, verbose=verbose)\n\n    return m, viol, obj, res\n</pre> def apply_inv(B, R, U, eps, tau):     \"\"\"Apply inverse\"\"\"     num = U.T @ B @ U     den = R + eps * tau     inv = U @ (num / den) @ U.T     return inv   def get_tau(B, R, U, eps, t_hi, t_lo=0.0, tol=1.0e-14):     \"\"\"bisection method...\"\"\"     num = U.T @ B @ U     root_est = np.inf     while np.abs(root_est) &gt; tol:         t = 0.5 * (t_lo + t_hi)         den = R + eps * t         root_est = t * np.linalg.norm(num / den) - 1.0         if root_est &gt; 0.0:             t_hi = t         else:             t_lo = t     return t   def proj(X, err, U, R, K, n, eps, t_hi):     tau = get_tau(err, R, U, eps, t_hi=t_hi)     inv = apply_inv(err, R, U, eps, tau)     At_inv = np.concatenate((K.T @ inv, K.T @ inv.T), axis=0)     P = X - At_inv     return P   def PP(rho0, rho1, alpha=1.0e-4, num_iters=500, eps=1.0e-10, verbose=False):     \"\"\"Apply Proximal Dual Hybrid Gradient to compute Earth Mover's Distance      Convergence is ensured when mu * tau * lambd_max(div), where div is     the matrix for the divergence operator.      m = [mx; my^T]      Boundary conditions are held by simply removing those \"ghost entries\"     mx[-1, :]   = 0     my^T[-1, :] = 0     \"\"\"     viol = np.zeros(num_iters)     obj = np.zeros(num_iters)     res = np.zeros(num_iters)     n = rho0.shape[0]     m = np.zeros((2 * (n - 1), n))  # m = [mx; my.T], x for i, y for j     z = np.zeros((2 * (n - 1), n))     K = construct_K(n)      \"\"\" Get SVD \"\"\"     U, S, Vt = np.linalg.svd(K.toarray(), full_matrices=True)     S = np.concatenate((S, np.zeros(n - S.shape[0])), axis=0)     R = np.zeros(U.shape)      for i in range(n):         for j in range(n):             R[i, j] += S[i] ** 2.0 + S[j] ** 2.0      for k in range(num_iters):         m_p = m.copy()          err = apply_div(z) + rho1 - rho0         err_norm = np.linalg.norm(err, ord=\"fro\")         if err_norm &gt; eps:             t_hi = ((2.0 * S[0]) ** 2.0) / (err_norm - eps)             m = proj(z, err, U, R, K, n, eps, t_hi=t_hi)         else:             m = z         z = z + shrink(2.0 * m - z, alpha) - m          viol, obj, res = update_stats(m, m_p, viol, obj, res, k, verbose=verbose)      return m, viol, obj, res In\u00a0[86]: Copied! <pre>import time\n\nrho0, rho1 = get_distributions(\"cat1.png\", \"cat2.png\")\nnum_trials = 10\nnum_iters = 20000\ntimes_pp = np.zeros(num_trials)\ntimes_pdhg = np.zeros(num_trials)\ntimes_gpdhg = np.zeros(num_trials)\n\nfor t in range(num_trials):\n    print(\"Trial {:2d} of {:2d}\".format(t + 1, num_trials))\n    print(\"Executing PP\")\n    start = time.time()\n    m_pp, viol_pp, obj_pp, res_pp = PP(rho0, rho1, num_iters=num_iters)\n    times_pp[t] = time.time() - start\n    print(\"Executing PDHG\")\n    start = time.time()\n    m_pdhg, viol_pdhg, obj_pdhg, res_pdhg = PDHG(rho0, rho1, num_iters=num_iters)\n    times_pdhg[t] = time.time() - start\n    print(\"Executing G-Prox PDHG\")\n    start = time.time()\n    m_gpdhg, viol_gpdhg, obj_gpdhg, res_gpdhg = GPDHG(rho0, rho1, num_iters=num_iters)\n    times_gpdhg[t] = time.time() - start\n\nprint(\"avg pp time    = \", np.mean(times_pp))\nprint(\"avg pdhg time  = \", np.mean(times_pdhg))\nprint(\"avg gpdhg time = \", np.mean(times_gpdhg))\n</pre> import time  rho0, rho1 = get_distributions(\"cat1.png\", \"cat2.png\") num_trials = 10 num_iters = 20000 times_pp = np.zeros(num_trials) times_pdhg = np.zeros(num_trials) times_gpdhg = np.zeros(num_trials)  for t in range(num_trials):     print(\"Trial {:2d} of {:2d}\".format(t + 1, num_trials))     print(\"Executing PP\")     start = time.time()     m_pp, viol_pp, obj_pp, res_pp = PP(rho0, rho1, num_iters=num_iters)     times_pp[t] = time.time() - start     print(\"Executing PDHG\")     start = time.time()     m_pdhg, viol_pdhg, obj_pdhg, res_pdhg = PDHG(rho0, rho1, num_iters=num_iters)     times_pdhg[t] = time.time() - start     print(\"Executing G-Prox PDHG\")     start = time.time()     m_gpdhg, viol_gpdhg, obj_gpdhg, res_gpdhg = GPDHG(rho0, rho1, num_iters=num_iters)     times_gpdhg[t] = time.time() - start  print(\"avg pp time    = \", np.mean(times_pp)) print(\"avg pdhg time  = \", np.mean(times_pdhg)) print(\"avg gpdhg time = \", np.mean(times_gpdhg)) <pre>Trial  1 of 10\nExecuting PP\nExecuting PDHG\nExecuting G-Prox PDHG\nTrial  2 of 10\nExecuting PP\nExecuting PDHG\nExecuting G-Prox PDHG\nTrial  3 of 10\nExecuting PP\nExecuting PDHG\nExecuting G-Prox PDHG\nTrial  4 of 10\nExecuting PP\nExecuting PDHG\nExecuting G-Prox PDHG\nTrial  5 of 10\nExecuting PP\nExecuting PDHG\nExecuting G-Prox PDHG\nTrial  6 of 10\nExecuting PP\nExecuting PDHG\nExecuting G-Prox PDHG\nTrial  7 of 10\nExecuting PP\nExecuting PDHG\nExecuting G-Prox PDHG\nTrial  8 of 10\nExecuting PP\nExecuting PDHG\nExecuting G-Prox PDHG\nTrial  9 of 10\nExecuting PP\nExecuting PDHG\nExecuting G-Prox PDHG\nTrial 10 of 10\nExecuting PP\nExecuting PDHG\nExecuting G-Prox PDHG\navg pp time    =  107.19988234043122\navg pdhg time  =  43.70859835147858\navg gpdhg time =  107.3787169456482\n</pre> In\u00a0[87]: Copied! <pre># Violation\nfig, ax = plt.subplots()\nplt.title(\"Violation $|div(m^k) + p^1 - p^0|_F $ \")\nplt.plot(viol_pp, color=\"k\")\nplt.plot(viol_pdhg, color=\"g\")\nplt.plot(viol_gpdhg, color=\"r\")\nplt.yscale(\"log\")\nplt.show()\n\n# Objective\nfig, ax = plt.subplots()\nplt.title(\"Objective $|m^k|_{1}$\")\nplt.plot(obj_pp, color=\"k\")\nplt.plot(obj_pdhg, color=\"g\")\nplt.plot(obj_gpdhg, color=\"r\")\nplt.show()\n\n# Residual\nfig, ax = plt.subplots()\nplt.title(\"Residual $|m^{k+1}-m^k|_F$\")\nplt.plot(res_pp, color=\"k\")\nplt.plot(res_pdhg, color=\"g\")\nplt.plot(res_gpdhg, color=\"r\")\nplt.yscale(\"log\")\nplt.show()\n</pre> # Violation fig, ax = plt.subplots() plt.title(\"Violation $|div(m^k) + p^1 - p^0|_F $ \") plt.plot(viol_pp, color=\"k\") plt.plot(viol_pdhg, color=\"g\") plt.plot(viol_gpdhg, color=\"r\") plt.yscale(\"log\") plt.show()  # Objective fig, ax = plt.subplots() plt.title(\"Objective $|m^k|_{1}$\") plt.plot(obj_pp, color=\"k\") plt.plot(obj_pdhg, color=\"g\") plt.plot(obj_gpdhg, color=\"r\") plt.show()  # Residual fig, ax = plt.subplots() plt.title(\"Residual $|m^{k+1}-m^k|_F$\") plt.plot(res_pp, color=\"k\") plt.plot(res_pdhg, color=\"g\") plt.plot(res_gpdhg, color=\"r\") plt.yscale(\"log\") plt.show() In\u00a0[88]: Copied! <pre>n = 256\nd = 8\nindices = d * np.arange(n / d)\n\nfor k, mm in enumerate([m_pp, m_gpdhg, m_pdhg]):\n    # Create quiver plot for PP\n    matrixi = -m_pp[\n        :n:d, 0::d\n    ]  # vertical axis gets flipped for pictures (counts from top rather than bottom)\n    matrixj = m_pp[n::d, 0::d].T\n    plt.figure()\n    plt.matshow(2 * rho0 - rho1)  # show both cats\n    plt.quiver(indices, indices, matrixj, matrixi)\n    plt.axis(\"off\")\n    if k == 0:\n        plt.savefig(\"../results/emd-div-cat.png\", bbox_inches=\"tight\")\n    plt.show()\n</pre> n = 256 d = 8 indices = d * np.arange(n / d)  for k, mm in enumerate([m_pp, m_gpdhg, m_pdhg]):     # Create quiver plot for PP     matrixi = -m_pp[         :n:d, 0::d     ]  # vertical axis gets flipped for pictures (counts from top rather than bottom)     matrixj = m_pp[n::d, 0::d].T     plt.figure()     plt.matshow(2 * rho0 - rho1)  # show both cats     plt.quiver(indices, indices, matrixj, matrixi)     plt.axis(\"off\")     if k == 0:         plt.savefig(\"../results/emd-div-cat.png\", bbox_inches=\"tight\")     plt.show() <pre>&lt;Figure size 640x480 with 0 Axes&gt;</pre> <pre>&lt;Figure size 640x480 with 0 Axes&gt;</pre> <pre>&lt;Figure size 640x480 with 0 Axes&gt;</pre> In\u00a0[89]: Copied! <pre>filename = \"../results/emd-viol-plots.csv\"\nwith open(filename, \"w\") as csv_file:\n    for k in range(len(viol_pp)):\n        if k % 5 == 0:\n            csv_file.write(\"%0.5e,%0.5e,%0.5e\\n\" % (viol_pp[k], viol_pdhg[k], viol_gpdhg[k]))\nfilename = \"../results/emd-obj-plots.csv\"\nwith open(filename, \"w\") as csv_file:\n    for k in range(len(obj_pp)):\n        if k % 5 == 0:\n            csv_file.write(\"%0.5e,%0.5e,%0.5e\\n\" % (obj_pp[k], obj_pdhg[k], obj_gpdhg[k]))\nfilename = \"../results/emd-res-plots.csv\"\nwith open(filename, \"w\") as csv_file:\n    for k in range(len(res_pp)):\n        if k % 5 == 0:\n            csv_file.write(\"%0.5e,%0.5e,%0.5e\\n\" % (res_pp[k], res_pdhg[k], res_gpdhg[k]))\n\nfilename = \"../results/emd-times.tex\"\nwith open(filename, \"w\") as csv_file:\n    csv_file.write(\"\\\\def\\\\emdTimePP{%0.2f}\" % (np.mean(times_pp)))\n    csv_file.write(\"\\\\def\\\\emdTimeGPDHG{%0.2f}\" % (np.mean(times_gpdhg)))\n    csv_file.write(\"\\\\def\\\\emdTimePDHG{%0.2f}\" % (np.mean(times_pdhg)))\n    csv_file.write(\"\\\\def\\\\emdTimePPoverGPDHG{%0.1f}\" % (np.mean(times_pp) / np.mean(times_gpdhg)))\n    csv_file.write(\"\\\\def\\\\emdTimePPoverPDHG{%0.1f}\" % (np.mean(times_pp) / np.mean(times_pdhg)))\n\nprint(\"Plots have been saved.\")\n</pre> filename = \"../results/emd-viol-plots.csv\" with open(filename, \"w\") as csv_file:     for k in range(len(viol_pp)):         if k % 5 == 0:             csv_file.write(\"%0.5e,%0.5e,%0.5e\\n\" % (viol_pp[k], viol_pdhg[k], viol_gpdhg[k])) filename = \"../results/emd-obj-plots.csv\" with open(filename, \"w\") as csv_file:     for k in range(len(obj_pp)):         if k % 5 == 0:             csv_file.write(\"%0.5e,%0.5e,%0.5e\\n\" % (obj_pp[k], obj_pdhg[k], obj_gpdhg[k])) filename = \"../results/emd-res-plots.csv\" with open(filename, \"w\") as csv_file:     for k in range(len(res_pp)):         if k % 5 == 0:             csv_file.write(\"%0.5e,%0.5e,%0.5e\\n\" % (res_pp[k], res_pdhg[k], res_gpdhg[k]))  filename = \"../results/emd-times.tex\" with open(filename, \"w\") as csv_file:     csv_file.write(\"\\\\def\\\\emdTimePP{%0.2f}\" % (np.mean(times_pp)))     csv_file.write(\"\\\\def\\\\emdTimeGPDHG{%0.2f}\" % (np.mean(times_gpdhg)))     csv_file.write(\"\\\\def\\\\emdTimePDHG{%0.2f}\" % (np.mean(times_pdhg)))     csv_file.write(\"\\\\def\\\\emdTimePPoverGPDHG{%0.1f}\" % (np.mean(times_pp) / np.mean(times_gpdhg)))     csv_file.write(\"\\\\def\\\\emdTimePPoverPDHG{%0.1f}\" % (np.mean(times_pp) / np.mean(times_pdhg)))  print(\"Plots have been saved.\") <pre>Plots have been saved.\n</pre>"},{"location":"notebooks/earth_movers_distance/#earth-movers-distance","title":"Earth Mover's Distance\u00b6","text":""},{"location":"notebooks/earth_movers_distance/#code-for-comparison-method-pdhg","title":"Code for Comparison Method PDHG\u00b6","text":""},{"location":"notebooks/earth_movers_distance/#pp","title":"PP\u00b6","text":""},{"location":"notebooks/earth_movers_distance/#pytests","title":"PyTests\u00b6","text":""},{"location":"notebooks/earth_movers_distance/#execute-experiment","title":"Execute Experiment\u00b6","text":""},{"location":"notebooks/earth_movers_distance/#plot-densities-and-divergence","title":"Plot Densities and Divergence\u00b6","text":""},{"location":"notebooks/stable_matrix_completion/","title":"Matrix Completion","text":"In\u00a0[4]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\n\n\ndef svt(A, alpha):\n    U, S, V = np.linalg.svd(A, full_matrices=False)\n    S = np.sign(S) * np.maximum(np.abs(S) - alpha, 0)\n    return (U * S) @ V\n\n\ndef update_stats(X, X_p, M_obs, M, Omega, viol, obj, res, err, verbose=False):\n    \"\"\"Update arrays that store performance statistics.\"\"\"\n    viol.append(max(0, (np.linalg.norm(X.flat[Omega] - M_obs.flat[Omega]) - eps)) / eps)\n    obj.append(np.linalg.norm(X, ord=\"nuc\"))\n    res.append(np.linalg.norm(X - X_p, ord=\"fro\") / np.linalg.norm(M, ord=\"fro\"))\n    err.append(np.linalg.norm(X - M, ord=\"fro\") / np.linalg.norm(M, ord=\"fro\"))\n    if len(viol) % 5 == 0 and verbose:\n        print(\n            \"[{:3d}] obj = {:0.5e}, res = {:0.3e},  viol = {:0.3e}\".format(\n                len(viol), obj[-1], res[-1], viol[-1]\n            )\n        )\n    return viol, obj, res, err\n\n\ndef create_mat(n, r, s):\n    \"\"\"Create Gaussian matrix\"\"\"\n    d_r = r * (2 * n - r)\n    s *= d_r\n    MR = np.random.normal(0, 1.0, size=(n, r))\n    ML = np.random.normal(0, 1.0, size=(n, r))\n    M = ML @ MR.T\n    N = np.random.normal(0, 0.25, size=(s))\n    Omega = np.random.choice(np.arange(n * n), size=s, replace=False)\n    M_obs = np.zeros(M.shape)\n    M_obs.flat[Omega] = M.flat[Omega] + N\n    return M, M_obs, N, Omega\n\n\ndef ball_proj(X, eps, Omega):\n    \"\"\"Project onto ball w.r.t. Frobenius norm\"\"\"\n    P = X.copy()\n    norm = np.linalg.norm(X.flat[Omega])\n    if norm &gt; eps:\n        P.flat[Omega] = X.flat[Omega] * eps / norm\n    return P\n</pre> import numpy as np import matplotlib.pyplot as plt   def svt(A, alpha):     U, S, V = np.linalg.svd(A, full_matrices=False)     S = np.sign(S) * np.maximum(np.abs(S) - alpha, 0)     return (U * S) @ V   def update_stats(X, X_p, M_obs, M, Omega, viol, obj, res, err, verbose=False):     \"\"\"Update arrays that store performance statistics.\"\"\"     viol.append(max(0, (np.linalg.norm(X.flat[Omega] - M_obs.flat[Omega]) - eps)) / eps)     obj.append(np.linalg.norm(X, ord=\"nuc\"))     res.append(np.linalg.norm(X - X_p, ord=\"fro\") / np.linalg.norm(M, ord=\"fro\"))     err.append(np.linalg.norm(X - M, ord=\"fro\") / np.linalg.norm(M, ord=\"fro\"))     if len(viol) % 5 == 0 and verbose:         print(             \"[{:3d}] obj = {:0.5e}, res = {:0.3e},  viol = {:0.3e}\".format(                 len(viol), obj[-1], res[-1], viol[-1]             )         )     return viol, obj, res, err   def create_mat(n, r, s):     \"\"\"Create Gaussian matrix\"\"\"     d_r = r * (2 * n - r)     s *= d_r     MR = np.random.normal(0, 1.0, size=(n, r))     ML = np.random.normal(0, 1.0, size=(n, r))     M = ML @ MR.T     N = np.random.normal(0, 0.25, size=(s))     Omega = np.random.choice(np.arange(n * n), size=s, replace=False)     M_obs = np.zeros(M.shape)     M_obs.flat[Omega] = M.flat[Omega] + N     return M, M_obs, N, Omega   def ball_proj(X, eps, Omega):     \"\"\"Project onto ball w.r.t. Frobenius norm\"\"\"     P = X.copy()     norm = np.linalg.norm(X.flat[Omega])     if norm &gt; eps:         P.flat[Omega] = X.flat[Omega] * eps / norm     return P In\u00a0[5]: Copied! <pre>def PG(M_obs, M, Omega, eps, tau=1.0e-1, alpha=1.0, tol=1e-3, max_iters=1000, verbose=False):\n    \"\"\"Execute ???\n    1.5e-5*len(Omega)\n    \"\"\"\n    viol = []\n    obj = []\n    res = []\n    err = []\n    X = M_obs.copy()\n    converge = False\n    while not converge:\n        X_p = X.copy()\n\n        X.flat[Omega] -= alpha * (X - M_obs).flat[Omega]\n        X = svt(X, tau * alpha)\n\n        viol, obj, res, err = update_stats(\n            X, X_p, M_obs, M, Omega, viol, obj, res, err, verbose=verbose\n        )\n        converge = res[-1] &lt; tol or len(res) == max_iters\n\n    return X, viol, obj, res, err\n\n\ndef VASALM(M_obs, M, Omega, eps, alpha=1e-2, eta=3.0, tol=1.0e-3, max_iters=1000, verbose=False):\n    \"\"\"alpha =1e-2\"\"\"\n    viol = []\n    obj = []\n    res = []\n    err = []\n    X = M_obs.copy()\n    Lambd = np.zeros(M_obs.shape)\n\n    converge = False\n    while not converge:\n        X_p = X.copy()\n        N = ball_proj(Lambd / alpha + M_obs - X, eps, Omega)\n        Lambd = Lambd - alpha * (X + N - M_obs)\n        X = svt(X + Lambd / (alpha * eta), 1.0 / (alpha * eta))\n        Lambd = Lambd + alpha * (X_p - X)\n\n        viol, obj, res, err = update_stats(\n            X, X_p, M_obs, M, Omega, viol, obj, res, err, verbose=verbose\n        )\n        converge = res[-1] &lt; tol or len(res) == max_iters\n\n    return X, viol, obj, res, err\n\n\ndef SPG(M_obs, M, Omega, eps, mu=1.0e1, tol=1e-3, max_iters=1000, verbose=False):\n    \"\"\"Execute ???\"\"\"\n    viol = []\n    obj = []\n    res = []\n    err = []\n    X = M_obs.copy()\n    OmegaC = list(set(range(X.size)) - set(Omega))\n\n    converge = False\n    while not converge:\n        X_p = X.copy()\n        Y = svt(X, mu)\n        norm = np.linalg.norm((M_obs - Y).flat[Omega])\n        theta = (norm - eps) / (mu * eps)\n\n        X.flat[Omega] = (mu * theta * M_obs.flat[Omega] + Y.flat[Omega]) / (1.0 + mu * theta)\n        X.flat[OmegaC] = Y.flat[OmegaC]\n\n        viol, obj, res, err = update_stats(\n            X, X_p, M_obs, M, Omega, viol, obj, res, err, verbose=verbose\n        )\n        converge = res[-1] &lt; tol or len(res) == max_iters\n\n    return X, viol, obj, res, err\n\n\ndef PP(M_obs, M, Omega, eps, alpha=5.0e1, tol=1e-3, max_iters=1000, verbose=False):\n    \"\"\"Execute ???\"\"\"\n    viol = []\n    obj = []\n    res = []\n    err = []\n    X = M_obs.copy()\n    Z = M_obs.copy()\n    OmegaC = list(set(range(X.size)) - set(Omega))\n\n    converge = False\n    while not converge:\n        X_p = X.copy()\n        Z = Z + svt(2.0 * X - Z, alpha) - X\n        norm = np.linalg.norm(Z.flat[Omega] - M_obs.flat[Omega])\n        if norm &gt; eps:\n            X.flat[OmegaC] = Z.flat[OmegaC]\n            X.flat[Omega] = ((norm - eps) * M_obs.flat[Omega] + eps * Z.flat[Omega]) / norm\n        else:\n            X = Z\n        viol, obj, res, err = update_stats(\n            X, X_p, M_obs, M, Omega, viol, obj, res, err, verbose=verbose\n        )\n        converge = res[-1] &lt; tol or len(res) == max_iters\n\n    return X, viol, obj, res, err\n</pre> def PG(M_obs, M, Omega, eps, tau=1.0e-1, alpha=1.0, tol=1e-3, max_iters=1000, verbose=False):     \"\"\"Execute ???     1.5e-5*len(Omega)     \"\"\"     viol = []     obj = []     res = []     err = []     X = M_obs.copy()     converge = False     while not converge:         X_p = X.copy()          X.flat[Omega] -= alpha * (X - M_obs).flat[Omega]         X = svt(X, tau * alpha)          viol, obj, res, err = update_stats(             X, X_p, M_obs, M, Omega, viol, obj, res, err, verbose=verbose         )         converge = res[-1] &lt; tol or len(res) == max_iters      return X, viol, obj, res, err   def VASALM(M_obs, M, Omega, eps, alpha=1e-2, eta=3.0, tol=1.0e-3, max_iters=1000, verbose=False):     \"\"\"alpha =1e-2\"\"\"     viol = []     obj = []     res = []     err = []     X = M_obs.copy()     Lambd = np.zeros(M_obs.shape)      converge = False     while not converge:         X_p = X.copy()         N = ball_proj(Lambd / alpha + M_obs - X, eps, Omega)         Lambd = Lambd - alpha * (X + N - M_obs)         X = svt(X + Lambd / (alpha * eta), 1.0 / (alpha * eta))         Lambd = Lambd + alpha * (X_p - X)          viol, obj, res, err = update_stats(             X, X_p, M_obs, M, Omega, viol, obj, res, err, verbose=verbose         )         converge = res[-1] &lt; tol or len(res) == max_iters      return X, viol, obj, res, err   def SPG(M_obs, M, Omega, eps, mu=1.0e1, tol=1e-3, max_iters=1000, verbose=False):     \"\"\"Execute ???\"\"\"     viol = []     obj = []     res = []     err = []     X = M_obs.copy()     OmegaC = list(set(range(X.size)) - set(Omega))      converge = False     while not converge:         X_p = X.copy()         Y = svt(X, mu)         norm = np.linalg.norm((M_obs - Y).flat[Omega])         theta = (norm - eps) / (mu * eps)          X.flat[Omega] = (mu * theta * M_obs.flat[Omega] + Y.flat[Omega]) / (1.0 + mu * theta)         X.flat[OmegaC] = Y.flat[OmegaC]          viol, obj, res, err = update_stats(             X, X_p, M_obs, M, Omega, viol, obj, res, err, verbose=verbose         )         converge = res[-1] &lt; tol or len(res) == max_iters      return X, viol, obj, res, err   def PP(M_obs, M, Omega, eps, alpha=5.0e1, tol=1e-3, max_iters=1000, verbose=False):     \"\"\"Execute ???\"\"\"     viol = []     obj = []     res = []     err = []     X = M_obs.copy()     Z = M_obs.copy()     OmegaC = list(set(range(X.size)) - set(Omega))      converge = False     while not converge:         X_p = X.copy()         Z = Z + svt(2.0 * X - Z, alpha) - X         norm = np.linalg.norm(Z.flat[Omega] - M_obs.flat[Omega])         if norm &gt; eps:             X.flat[OmegaC] = Z.flat[OmegaC]             X.flat[Omega] = ((norm - eps) * M_obs.flat[Omega] + eps * Z.flat[Omega]) / norm         else:             X = Z         viol, obj, res, err = update_stats(             X, X_p, M_obs, M, Omega, viol, obj, res, err, verbose=verbose         )         converge = res[-1] &lt; tol or len(res) == max_iters      return X, viol, obj, res, err In\u00a0[\u00a0]: Copied! <pre>trials = 10\nr = [10, 50]\ns = [5, 4]\nn = 1000\ntol = 1.0e-20\niters = 200\n\nfor i in range(len(r)):\n    print(\"Rank \", r[i], \" plots\")\n\n    viol = np.zeros((3, trials, iters))\n    obj = np.zeros((3, trials, iters))\n    res = np.zeros((3, trials, iters))\n    err = np.zeros((3, trials, iters))\n\n    for t in range(trials):\n        print(\"Trial: %2d of %2d\" % (t + 1, trials))\n        np.random.seed(t)\n        M, M_obs, N, Omega = create_mat(n, r[i], s[i])\n        eps = np.linalg.norm(N)\n\n        _, viol[0, t, :], obj[0, t, :], res[0, t, :], err[0, t, :] = PP(\n            M_obs, M, Omega, eps, tol=tol, max_iters=iters, verbose=True\n        )\n        _, viol[1, t, :], obj[1, t, :], res[1, t, :], err[1, t, :] = VASALM(\n            M_obs, M, Omega, eps, tol=tol, max_iters=iters, verbose=True\n        )\n        _, viol[2, t, :], obj[2, t, :], res[2, t, :], err[2, t, :] = SPG(\n            M_obs, M, Omega, eps, tol=tol, max_iters=iters, verbose=True\n        )\n\n    viol_pp = np.median(viol[0, :, :], axis=0)\n    viol_vasalm = np.median(viol[1, :, :], axis=0)\n    viol_spg = np.median(viol[2, :, :], axis=0)\n\n    obj_pp = np.median(obj[0, :, :], axis=0)\n    obj_vasalm = np.median(obj[1, :, :], axis=0)\n    obj_spg = np.median(obj[2, :, :], axis=0)\n\n    res_pp = np.median(res[0, :, :], axis=0)\n    res_vasalm = np.median(res[1, :, :], axis=0)\n    res_spg = np.median(res[2, :, :], axis=0)\n\n    err_pp = np.median(err[0, :, :], axis=0)\n    err_vasalm = np.median(err[1, :, :], axis=0)\n    err_spg = np.median(err[2, :, :], axis=0)\n\n    filename = \"../results/smc-obj-plots-\" + str(r[i]) + \".csv\"\n    with open(filename, \"w\") as csv_file:\n        for k in range(iters):\n            csv_file.write(\"%0.5e,%0.5e,%0.5e\\n\" % (obj_pp[k], obj_vasalm[k], obj_spg[k]))\n    filename = \"../results/smc-viol-plots-\" + str(r[i]) + \".csv\"\n    with open(filename, \"w\") as csv_file:\n        for k in range(iters):\n            csv_file.write(\"%0.5e,%0.5e,%0.5e\\n\" % (viol_pp[k], viol_vasalm[k], viol_spg[k]))\n    filename = \"../results/smc-res-plots-\" + str(r[i]) + \".csv\"\n    with open(filename, \"w\") as csv_file:\n        for k in range(iters):\n            csv_file.write(\"%0.5e,%0.5e,%0.5e\\n\" % (res_pp[k], res_vasalm[k], res_spg[k]))\n\n    # Violation\n    fig, ax = plt.subplots()\n    plt.title(\"Violation $\\\\|\\\\mathcal{P}_{\\\\Omega}(X^k - M^k)\\\\|_F/\\\\|X^k\\\\|_F$\")\n    plt.plot(viol_pp, color=\"b\")\n    plt.plot(viol_spg, color=\"k\")\n    plt.plot(viol_vasalm, color=\"r\")\n    plt.yscale(\"log\")\n    plt.show()\n\n    # Objective\n    fig, ax = plt.subplots()\n    plt.title(\"Objective $\\\\|X^k\\\\|_\\\\star$\")\n    plt.plot(obj_pp, color=\"b\")\n    plt.plot(obj_spg, color=\"k\")\n    plt.plot(obj_vasalm, color=\"r\")\n    plt.yscale(\"log\")\n    plt.show()\n\n    # Residual\n    fig, ax = plt.subplots()\n    plt.title(\"Residual $\\\\|X^{k+1}-X^k\\\\|_F$\")\n    plt.plot(res_pp, color=\"b\")\n    plt.plot(res_spg, color=\"k\")\n    plt.plot(res_vasalm, color=\"r\")\n    plt.yscale(\"log\")\n    plt.show()\n\n    # Error\n    fig, ax = plt.subplots()\n    plt.title(\"Error $\\\\|X^k - M\\\\|_F / \\\\|M\\\\|_F$\")\n    plt.plot(err_pp, color=\"b\")\n    plt.plot(err_spg, color=\"k\")\n    plt.plot(err_vasalm, color=\"r\")\n    plt.yscale(\"log\")\n    plt.show()\n\nprint(\"All methods have completed.\")\n</pre> trials = 10 r = [10, 50] s = [5, 4] n = 1000 tol = 1.0e-20 iters = 200  for i in range(len(r)):     print(\"Rank \", r[i], \" plots\")      viol = np.zeros((3, trials, iters))     obj = np.zeros((3, trials, iters))     res = np.zeros((3, trials, iters))     err = np.zeros((3, trials, iters))      for t in range(trials):         print(\"Trial: %2d of %2d\" % (t + 1, trials))         np.random.seed(t)         M, M_obs, N, Omega = create_mat(n, r[i], s[i])         eps = np.linalg.norm(N)          _, viol[0, t, :], obj[0, t, :], res[0, t, :], err[0, t, :] = PP(             M_obs, M, Omega, eps, tol=tol, max_iters=iters, verbose=True         )         _, viol[1, t, :], obj[1, t, :], res[1, t, :], err[1, t, :] = VASALM(             M_obs, M, Omega, eps, tol=tol, max_iters=iters, verbose=True         )         _, viol[2, t, :], obj[2, t, :], res[2, t, :], err[2, t, :] = SPG(             M_obs, M, Omega, eps, tol=tol, max_iters=iters, verbose=True         )      viol_pp = np.median(viol[0, :, :], axis=0)     viol_vasalm = np.median(viol[1, :, :], axis=0)     viol_spg = np.median(viol[2, :, :], axis=0)      obj_pp = np.median(obj[0, :, :], axis=0)     obj_vasalm = np.median(obj[1, :, :], axis=0)     obj_spg = np.median(obj[2, :, :], axis=0)      res_pp = np.median(res[0, :, :], axis=0)     res_vasalm = np.median(res[1, :, :], axis=0)     res_spg = np.median(res[2, :, :], axis=0)      err_pp = np.median(err[0, :, :], axis=0)     err_vasalm = np.median(err[1, :, :], axis=0)     err_spg = np.median(err[2, :, :], axis=0)      filename = \"../results/smc-obj-plots-\" + str(r[i]) + \".csv\"     with open(filename, \"w\") as csv_file:         for k in range(iters):             csv_file.write(\"%0.5e,%0.5e,%0.5e\\n\" % (obj_pp[k], obj_vasalm[k], obj_spg[k]))     filename = \"../results/smc-viol-plots-\" + str(r[i]) + \".csv\"     with open(filename, \"w\") as csv_file:         for k in range(iters):             csv_file.write(\"%0.5e,%0.5e,%0.5e\\n\" % (viol_pp[k], viol_vasalm[k], viol_spg[k]))     filename = \"../results/smc-res-plots-\" + str(r[i]) + \".csv\"     with open(filename, \"w\") as csv_file:         for k in range(iters):             csv_file.write(\"%0.5e,%0.5e,%0.5e\\n\" % (res_pp[k], res_vasalm[k], res_spg[k]))      # Violation     fig, ax = plt.subplots()     plt.title(\"Violation $\\\\|\\\\mathcal{P}_{\\\\Omega}(X^k - M^k)\\\\|_F/\\\\|X^k\\\\|_F$\")     plt.plot(viol_pp, color=\"b\")     plt.plot(viol_spg, color=\"k\")     plt.plot(viol_vasalm, color=\"r\")     plt.yscale(\"log\")     plt.show()      # Objective     fig, ax = plt.subplots()     plt.title(\"Objective $\\\\|X^k\\\\|_\\\\star$\")     plt.plot(obj_pp, color=\"b\")     plt.plot(obj_spg, color=\"k\")     plt.plot(obj_vasalm, color=\"r\")     plt.yscale(\"log\")     plt.show()      # Residual     fig, ax = plt.subplots()     plt.title(\"Residual $\\\\|X^{k+1}-X^k\\\\|_F$\")     plt.plot(res_pp, color=\"b\")     plt.plot(res_spg, color=\"k\")     plt.plot(res_vasalm, color=\"r\")     plt.yscale(\"log\")     plt.show()      # Error     fig, ax = plt.subplots()     plt.title(\"Error $\\\\|X^k - M\\\\|_F / \\\\|M\\\\|_F$\")     plt.plot(err_pp, color=\"b\")     plt.plot(err_spg, color=\"k\")     plt.plot(err_vasalm, color=\"r\")     plt.yscale(\"log\")     plt.show()  print(\"All methods have completed.\") In\u00a0[\u00a0]: Copied! <pre>methods = [\"PP\", \"VASALM\", \"SPG\"]\nr = [10, 50, 100]\nlabels = [\"a\", \"b\", \"c\"]  # use letters for each rank when saving to file\ns = [5, 4, 3]\ntol = 1.0e-5\ntrials = 10\n\ntable_iters = np.zeros((3, len(r), trials))\ntable_viol = np.zeros((3, len(r), trials))\ntable_obj = np.zeros((3, len(r), trials))\n\nfor i in range(len(r)):\n    print(\"Rank: %3d\" % r[i])\n    for t in range(trials):\n        print(\"Trial: %2d of %2d\" % (t + 1, trials))\n        np.random.seed(t)\n        M, M_obs, N, Omega = create_mat(n, r[i], s[i])\n        eps = np.linalg.norm(N)\n\n        _, viol_pp, obj_pp, res_pp, err_pp = PP(M_obs, M, Omega, eps, tol=tol, verbose=False)\n        _, viol_vasalm, obj_vasalm, res_vasalm, err_vasalm = VASALM(\n            M_obs, M, Omega, eps, tol=tol, verbose=False\n        )\n        _, viol_spg, obj_spg, res_spg, err_spg = SPG(M_obs, M, Omega, eps, tol=tol, verbose=False)\n\n        table_iters[0, i, t] = len(viol_pp)\n        table_iters[1, i, t] = len(viol_vasalm)\n        table_iters[2, i, t] = len(viol_spg)\n\n        table_viol[0, i, t] = viol_pp[-1]\n        table_viol[1, i, t] = viol_vasalm[-1]\n        table_viol[2, i, t] = viol_spg[-1]\n\n        table_obj[0, i, t] = obj_pp[-1]\n        table_obj[1, i, t] = obj_vasalm[-1]\n        table_obj[2, i, t] = obj_spg[-1]\n\nfilename = \"../results/smc-table.tex\"\nwith open(filename, \"w\") as table_file:\n    for i, m in enumerate(methods):\n        for k, label in enumerate(labels):\n            table_file.write(\n                \"\\\\def\\\\smcIters\" + m + label + \"{%0.0d}\\n\" % (np.mean(table_iters[i, k, :]))\n            )\n            table_file.write(\n                \"\\\\def\\\\smcViol\" + m + label + \"{%0.2e}\\n\" % (np.mean(table_viol[i, k, :]))\n            )\n            table_file.write(\n                \"\\\\def\\\\smcObj\" + m + label + \"{%0.2e}\\n\" % (np.mean(table_obj[i, k, :]))\n            )\n\nprint(\"Data saved to file\")\n</pre> methods = [\"PP\", \"VASALM\", \"SPG\"] r = [10, 50, 100] labels = [\"a\", \"b\", \"c\"]  # use letters for each rank when saving to file s = [5, 4, 3] tol = 1.0e-5 trials = 10  table_iters = np.zeros((3, len(r), trials)) table_viol = np.zeros((3, len(r), trials)) table_obj = np.zeros((3, len(r), trials))  for i in range(len(r)):     print(\"Rank: %3d\" % r[i])     for t in range(trials):         print(\"Trial: %2d of %2d\" % (t + 1, trials))         np.random.seed(t)         M, M_obs, N, Omega = create_mat(n, r[i], s[i])         eps = np.linalg.norm(N)          _, viol_pp, obj_pp, res_pp, err_pp = PP(M_obs, M, Omega, eps, tol=tol, verbose=False)         _, viol_vasalm, obj_vasalm, res_vasalm, err_vasalm = VASALM(             M_obs, M, Omega, eps, tol=tol, verbose=False         )         _, viol_spg, obj_spg, res_spg, err_spg = SPG(M_obs, M, Omega, eps, tol=tol, verbose=False)          table_iters[0, i, t] = len(viol_pp)         table_iters[1, i, t] = len(viol_vasalm)         table_iters[2, i, t] = len(viol_spg)          table_viol[0, i, t] = viol_pp[-1]         table_viol[1, i, t] = viol_vasalm[-1]         table_viol[2, i, t] = viol_spg[-1]          table_obj[0, i, t] = obj_pp[-1]         table_obj[1, i, t] = obj_vasalm[-1]         table_obj[2, i, t] = obj_spg[-1]  filename = \"../results/smc-table.tex\" with open(filename, \"w\") as table_file:     for i, m in enumerate(methods):         for k, label in enumerate(labels):             table_file.write(                 \"\\\\def\\\\smcIters\" + m + label + \"{%0.0d}\\n\" % (np.mean(table_iters[i, k, :]))             )             table_file.write(                 \"\\\\def\\\\smcViol\" + m + label + \"{%0.2e}\\n\" % (np.mean(table_viol[i, k, :]))             )             table_file.write(                 \"\\\\def\\\\smcObj\" + m + label + \"{%0.2e}\\n\" % (np.mean(table_obj[i, k, :]))             )  print(\"Data saved to file\")"},{"location":"notebooks/stable_matrix_completion/#matrix-completion","title":"Matrix Completion\u00b6","text":""},{"location":"notebooks/stable_matrix_completion/#numerical-examples-to-generate-smc-plots","title":"Numerical Examples to generate SMC Plots\u00b6","text":""},{"location":"notebooks/stable_matrix_completion/#numerical-examples-to-generate-smc-table","title":"Numerical Examples to Generate SMC Table\u00b6","text":""},{"location":"notebooks/stable_principal_component_pursuit/","title":"Principal Component Pursuit","text":"In\u00a0[1]: Copied! <pre>from PIL import Image\nfrom IPython.display import display\nimport numpy as np\nimport cv2\nimport os\n\nwidth = 960\nheight = 540\nframes = 250\nskip = 1000 / frames\n\n\ndef save_all_frames(video_path, dir_path, basename, ext=\"png\"):\n    cap = cv2.VideoCapture(video_path)\n\n    if not cap.isOpened():\n        return\n\n    os.makedirs(dir_path, exist_ok=True)\n    base_path = os.path.join(dir_path, basename)\n\n    digit = len(str(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))))\n\n    n = 0\n    while n &lt; skip * frames:\n        ret, frame = cap.read()\n        if ret:\n            if n % skip == 0:\n                small_frame = cv2.resize(frame, (0, 0), fx=0.5, fy=0.5)\n                file_name = \"{}_{}.{}\".format(base_path, str(int(n / skip + 1)).zfill(digit), ext)\n                cv2.imwrite(file_name, small_frame)\n        else:\n            return\n        n += 1\n\n\nsave_all_frames(\"../data/PNNL_Parking_LOT.avi\", \"../data/frames/\", \"frame\")\nprint(\"frames saved\")\n</pre> from PIL import Image from IPython.display import display import numpy as np import cv2 import os  width = 960 height = 540 frames = 250 skip = 1000 / frames   def save_all_frames(video_path, dir_path, basename, ext=\"png\"):     cap = cv2.VideoCapture(video_path)      if not cap.isOpened():         return      os.makedirs(dir_path, exist_ok=True)     base_path = os.path.join(dir_path, basename)      digit = len(str(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))))      n = 0     while n &lt; skip * frames:         ret, frame = cap.read()         if ret:             if n % skip == 0:                 small_frame = cv2.resize(frame, (0, 0), fx=0.5, fy=0.5)                 file_name = \"{}_{}.{}\".format(base_path, str(int(n / skip + 1)).zfill(digit), ext)                 cv2.imwrite(file_name, small_frame)         else:             return         n += 1   save_all_frames(\"../data/PNNL_Parking_LOT.avi\", \"../data/frames/\", \"frame\") print(\"frames saved\") <pre>frames saved\n</pre> In\u00a0[2]: Copied! <pre>def display_frame(A, frame):\n    img = np.uint8(np.reshape(A[:, frame], (height, width)))\n    image = Image.fromarray(img, \"L\")\n    image = image.resize((320, 180))\n    display(image)\n\n\ndef save_frame(A, frame, filename):\n    img = np.uint8(np.reshape(A[:, frame], (height, width)))\n    image = Image.fromarray(img, \"L\")\n    image.save(filename)\n\n\ndef get_frame_num(frame):\n    if frame &lt; 9:\n        return \"00\" + str(frame + 1)\n    elif frame &lt; 99:\n        return \"0\" + str(frame + 1)\n    elif frame &lt; 999:\n        return str(frame + 1)\n    else:\n        assert False\n\n\ndef save_sample(M, L, S, frame=100):\n    file_name = \"../results/sample_frame_\" + str(frame)\n    save_frame(M, frame, file_name + \"_M.png\")\n    save_frame(L, frame, file_name + \"_L.png\")\n    save_frame(0.5 * (S + 255), frame, file_name + \"_S.png\")\n</pre> def display_frame(A, frame):     img = np.uint8(np.reshape(A[:, frame], (height, width)))     image = Image.fromarray(img, \"L\")     image = image.resize((320, 180))     display(image)   def save_frame(A, frame, filename):     img = np.uint8(np.reshape(A[:, frame], (height, width)))     image = Image.fromarray(img, \"L\")     image.save(filename)   def get_frame_num(frame):     if frame &lt; 9:         return \"00\" + str(frame + 1)     elif frame &lt; 99:         return \"0\" + str(frame + 1)     elif frame &lt; 999:         return str(frame + 1)     else:         assert False   def save_sample(M, L, S, frame=100):     file_name = \"../results/sample_frame_\" + str(frame)     save_frame(M, frame, file_name + \"_M.png\")     save_frame(L, frame, file_name + \"_L.png\")     save_frame(0.5 * (S + 255), frame, file_name + \"_S.png\") In\u00a0[3]: Copied! <pre>M = np.zeros((width * height, frames))\nfor k in range(frames):\n    image = Image.open(\"../data/frames/frame_\" + get_frame_num(k) + \".png\").convert(\"L\")\n    img = np.array(image)\n    M[:, k] = np.reshape(img, (height * width))\n\ndisplay_frame(M, 50)\nprint(\"M.shape = \", M.shape)\n</pre> M = np.zeros((width * height, frames)) for k in range(frames):     image = Image.open(\"../data/frames/frame_\" + get_frame_num(k) + \".png\").convert(\"L\")     img = np.array(image)     M[:, k] = np.reshape(img, (height * width))  display_frame(M, 50) print(\"M.shape = \", M.shape) <pre>M.shape =  (518400, 250)\n</pre> In\u00a0[4]: Copied! <pre>from scipy.sparse.linalg import svds\nimport scipy as sp\n\n\ndef shrink(x, alpha):\n    return np.sign(x) * np.maximum(np.abs(x) - alpha, 0)\n\n\ndef svt(A, alpha, num_s_vals=100, use_svd=True, use_sparse=False):\n    U, S, V = np.linalg.svd(A, full_matrices=False)\n    S = np.sign(S) * np.maximum(np.abs(S) - alpha, 0)\n    return (U * S) @ V\n\n\ndef ball_proj(X, eps):\n    \"\"\"Project onto ball w.r.t. Frobenius norm\"\"\"\n    norm = np.linalg.norm(X, ord=\"fro\")\n    if norm &gt; eps:\n        return X * eps / norm\n    else:\n        return X\n\n\ndef update_stats(viol, obj, res, XL, XL_p, XS, XS_p, M, lambd, eps, k, verbose=False):\n    res_k = np.linalg.norm(XL - XL_p, ord=\"fro\") ** 2.0\n    res_k += np.linalg.norm(XS - XS_p, ord=\"fro\") ** 2.0\n    res_k = res_k**0.5\n    res[k] = res_k / np.linalg.norm(M, ord=\"fro\")\n    obj[k] = np.linalg.norm(XL, ord=\"nuc\") + lambd * np.linalg.norm(XS, ord=1)\n    viol[k] = max(0.0, np.linalg.norm(XL + XS - M, ord=\"fro\") - eps) / eps\n\n    if verbose:\n        msg = \"%0.5d: obj = %0.4e, |X - X_p| = %0.5e  max(0, |XL + XS - M|_F - eps) = %0.5e\"\n        print(msg % (k, obj[k], res[k], viol[k]))\n        display_frame(XL, k % frames)\n        display_frame(0.5 * (XS + 255.0), k % frames)\n\n    return viol, obj, res\n</pre> from scipy.sparse.linalg import svds import scipy as sp   def shrink(x, alpha):     return np.sign(x) * np.maximum(np.abs(x) - alpha, 0)   def svt(A, alpha, num_s_vals=100, use_svd=True, use_sparse=False):     U, S, V = np.linalg.svd(A, full_matrices=False)     S = np.sign(S) * np.maximum(np.abs(S) - alpha, 0)     return (U * S) @ V   def ball_proj(X, eps):     \"\"\"Project onto ball w.r.t. Frobenius norm\"\"\"     norm = np.linalg.norm(X, ord=\"fro\")     if norm &gt; eps:         return X * eps / norm     else:         return X   def update_stats(viol, obj, res, XL, XL_p, XS, XS_p, M, lambd, eps, k, verbose=False):     res_k = np.linalg.norm(XL - XL_p, ord=\"fro\") ** 2.0     res_k += np.linalg.norm(XS - XS_p, ord=\"fro\") ** 2.0     res_k = res_k**0.5     res[k] = res_k / np.linalg.norm(M, ord=\"fro\")     obj[k] = np.linalg.norm(XL, ord=\"nuc\") + lambd * np.linalg.norm(XS, ord=1)     viol[k] = max(0.0, np.linalg.norm(XL + XS - M, ord=\"fro\") - eps) / eps      if verbose:         msg = \"%0.5d: obj = %0.4e, |X - X_p| = %0.5e  max(0, |XL + XS - M|_F - eps) = %0.5e\"         print(msg % (k, obj[k], res[k], viol[k]))         display_frame(XL, k % frames)         display_frame(0.5 * (XS + 255.0), k % frames)      return viol, obj, res In\u00a0[5]: Copied! <pre>def PP(M, lambd, eps, alpha=3.0e4, iters=30, verbose=False):\n    \"\"\"Execute Proximal Projection\"\"\"\n    # Initializations\n    res = np.zeros(iters)\n    viol = np.zeros(iters)\n    obj = np.zeros(iters)\n    ZL = M.copy()\n    ZS = np.zeros(M.shape)\n    XL = M.copy()\n    XS = np.zeros(M.shape)\n\n    for k in range(iters):\n        XL_p = XL.copy()\n        XS_p = XS.copy()\n        ZL = ZL + svt(2 * XL - ZL, alpha) - XL\n        ZS = ZS + shrink(2 * XS - ZS, lambd * alpha) - XS\n        AW_norm = np.linalg.norm(ZL + ZS - M, ord=\"fro\")\n        mu = np.maximum(0, (AW_norm - eps) / (2 * AW_norm))\n        XL = ZL - mu * (ZL + ZS - M)\n        XS = ZS - mu * (ZL + ZS - M)\n\n        viol, obj, res = update_stats(\n            viol, obj, res, XL, XL_p, XS, XS_p, M, lambd, eps, k, verbose=verbose\n        )\n\n    return XL, XS, res, viol, obj\n\n\ndef PG(M, lambd, eps, alpha=1.0e3, iters=30, verbose=False):\n    \"\"\"Execute Proximal Gradient\n\n    Magic numbers:\n        too small  - 1e3\n        too big    - 1e5\n        just right - 8e3\n    \"\"\"\n    res = np.zeros(iters)\n    viol = np.zeros(iters)\n    obj = np.zeros(iters)\n    XL = M.copy()\n    XS = np.zeros(M.shape)\n\n    for k in range(iters):\n        XL_p = XL.copy()\n        XS_p = XS.copy()\n        XL = svt(M - XS, alpha)\n        XS = shrink(M - XL, lambd * alpha)\n\n        viol, obj, res = update_stats(\n            viol, obj, res, XL, XL_p, XS, XS_p, M, lambd, eps, k, verbose=verbose\n        )\n\n    return XL, XS, res, viol, obj\n\n\ndef get_root(A, lambd, mu, eps, tol=1.0e-8):\n    \"\"\"Compute roots for PGS\"\"\"\n    if np.linalg.norm(A, ord=\"fro\") &lt;= eps:\n        return 0.0\n    else:\n        t_lo = 0.0\n        t_hi = min(\n            A.shape[0] * A.shape[1] * lambd * eps,\n            np.abs(np.linalg.norm(A, ord=\"fro\") - eps) / (mu * eps),\n        )\n        root_est = np.inf\n        tol *= eps\n\n        while np.abs(root_est) &gt; tol:\n            t = 0.5 * (t_lo + t_hi)\n            root_est = (\n                np.linalg.norm(\n                    np.minimum(lambd / t * np.ones(A.shape), A / (1.0 + mu * t)), ord=\"fro\"\n                )\n                - eps\n            )\n            if root_est &lt; 0.0:\n                t_hi = t\n            else:\n                t_lo = t\n        return t\n\n\ndef SPG(M, lambd, eps, mu=1.73755e5, iters=30, verbose=False):\n    \"\"\"Execute Proximal Gradient on Smoothed Problem\n\n    opt_est = 1.73755e6\n    \"\"\"\n    res = np.zeros(iters)\n    viol = np.zeros(iters)\n    obj = np.zeros(iters)\n    XL = M.copy()\n    XS = np.zeros(M.shape)\n    mu /= min(M.shape[0], M.shape[1])\n    print(\"mu = \", mu)\n\n    for k in range(iters):\n        XL_p = XL.copy()\n        XS_p = XS.copy()\n        Q = svt(XL, mu)\n        theta = get_root(np.abs(M - Q), lambd, mu, eps)\n        if theta &gt; 0:\n            XS = shrink(M - Q, lambd * (1.0 + mu * theta) / theta)\n        else:\n            XS = np.zeros(XS.shape)\n        XL = (mu * theta * (M - XS) + Q) / (1.0 + mu * theta)\n\n        viol, obj, res = update_stats(\n            viol, obj, res, XL, XL_p, XS, XS_p, M, lambd, eps, k, verbose=verbose\n        )\n\n    return XL, XS, res, viol, obj\n\n\ndef VASALM(M, lambd, eps, alpha=1.0e-5, eta=3.0, iters=30, verbose=False):\n    \"\"\"Execute Variant of Alternative Splitting Augmented Lagrangian Method\"\"\"\n    res = np.zeros(iters)\n    viol = np.zeros(iters)\n    obj = np.zeros(iters)\n    XL = M.copy()\n    XS = np.zeros(M.shape)\n    Lambd = np.zeros(M.shape)\n\n    for k in range(iters):\n        XL_p = XL.copy()\n        XS_p = XS.copy()\n        Lambd_p = Lambd.copy()\n        N = ball_proj(Lambd / alpha + M - XS - XL, eps)\n        Lambd = Lambd - alpha * (XL + XS + N - M)\n        XS = shrink(XS + Lambd / (alpha * eta), lambd / (alpha * eta))\n        XL = svt(XL + Lambd / (alpha * eta), 1.0 / (alpha * eta))\n        Lambd = Lambd + alpha * (XL_p - XL) + alpha * (XS_p - XS)\n\n        viol, obj, res = update_stats(\n            viol, obj, res, XL, XL_p, XS, XS_p, M, lambd, eps, k, verbose=verbose\n        )\n\n    return XL, XS, res, viol, obj\n</pre> def PP(M, lambd, eps, alpha=3.0e4, iters=30, verbose=False):     \"\"\"Execute Proximal Projection\"\"\"     # Initializations     res = np.zeros(iters)     viol = np.zeros(iters)     obj = np.zeros(iters)     ZL = M.copy()     ZS = np.zeros(M.shape)     XL = M.copy()     XS = np.zeros(M.shape)      for k in range(iters):         XL_p = XL.copy()         XS_p = XS.copy()         ZL = ZL + svt(2 * XL - ZL, alpha) - XL         ZS = ZS + shrink(2 * XS - ZS, lambd * alpha) - XS         AW_norm = np.linalg.norm(ZL + ZS - M, ord=\"fro\")         mu = np.maximum(0, (AW_norm - eps) / (2 * AW_norm))         XL = ZL - mu * (ZL + ZS - M)         XS = ZS - mu * (ZL + ZS - M)          viol, obj, res = update_stats(             viol, obj, res, XL, XL_p, XS, XS_p, M, lambd, eps, k, verbose=verbose         )      return XL, XS, res, viol, obj   def PG(M, lambd, eps, alpha=1.0e3, iters=30, verbose=False):     \"\"\"Execute Proximal Gradient      Magic numbers:         too small  - 1e3         too big    - 1e5         just right - 8e3     \"\"\"     res = np.zeros(iters)     viol = np.zeros(iters)     obj = np.zeros(iters)     XL = M.copy()     XS = np.zeros(M.shape)      for k in range(iters):         XL_p = XL.copy()         XS_p = XS.copy()         XL = svt(M - XS, alpha)         XS = shrink(M - XL, lambd * alpha)          viol, obj, res = update_stats(             viol, obj, res, XL, XL_p, XS, XS_p, M, lambd, eps, k, verbose=verbose         )      return XL, XS, res, viol, obj   def get_root(A, lambd, mu, eps, tol=1.0e-8):     \"\"\"Compute roots for PGS\"\"\"     if np.linalg.norm(A, ord=\"fro\") &lt;= eps:         return 0.0     else:         t_lo = 0.0         t_hi = min(             A.shape[0] * A.shape[1] * lambd * eps,             np.abs(np.linalg.norm(A, ord=\"fro\") - eps) / (mu * eps),         )         root_est = np.inf         tol *= eps          while np.abs(root_est) &gt; tol:             t = 0.5 * (t_lo + t_hi)             root_est = (                 np.linalg.norm(                     np.minimum(lambd / t * np.ones(A.shape), A / (1.0 + mu * t)), ord=\"fro\"                 )                 - eps             )             if root_est &lt; 0.0:                 t_hi = t             else:                 t_lo = t         return t   def SPG(M, lambd, eps, mu=1.73755e5, iters=30, verbose=False):     \"\"\"Execute Proximal Gradient on Smoothed Problem      opt_est = 1.73755e6     \"\"\"     res = np.zeros(iters)     viol = np.zeros(iters)     obj = np.zeros(iters)     XL = M.copy()     XS = np.zeros(M.shape)     mu /= min(M.shape[0], M.shape[1])     print(\"mu = \", mu)      for k in range(iters):         XL_p = XL.copy()         XS_p = XS.copy()         Q = svt(XL, mu)         theta = get_root(np.abs(M - Q), lambd, mu, eps)         if theta &gt; 0:             XS = shrink(M - Q, lambd * (1.0 + mu * theta) / theta)         else:             XS = np.zeros(XS.shape)         XL = (mu * theta * (M - XS) + Q) / (1.0 + mu * theta)          viol, obj, res = update_stats(             viol, obj, res, XL, XL_p, XS, XS_p, M, lambd, eps, k, verbose=verbose         )      return XL, XS, res, viol, obj   def VASALM(M, lambd, eps, alpha=1.0e-5, eta=3.0, iters=30, verbose=False):     \"\"\"Execute Variant of Alternative Splitting Augmented Lagrangian Method\"\"\"     res = np.zeros(iters)     viol = np.zeros(iters)     obj = np.zeros(iters)     XL = M.copy()     XS = np.zeros(M.shape)     Lambd = np.zeros(M.shape)      for k in range(iters):         XL_p = XL.copy()         XS_p = XS.copy()         Lambd_p = Lambd.copy()         N = ball_proj(Lambd / alpha + M - XS - XL, eps)         Lambd = Lambd - alpha * (XL + XS + N - M)         XS = shrink(XS + Lambd / (alpha * eta), lambd / (alpha * eta))         XL = svt(XL + Lambd / (alpha * eta), 1.0 / (alpha * eta))         Lambd = Lambd + alpha * (XL_p - XL) + alpha * (XS_p - XS)          viol, obj, res = update_stats(             viol, obj, res, XL, XL_p, XS, XS_p, M, lambd, eps, k, verbose=verbose         )      return XL, XS, res, viol, obj In\u00a0[\u00a0]: Copied! <pre>iters = 30\nlambd = (M.shape[0]) ** -0.5\neps = 0.10 * (M.size**0.5) * np.std(M)\nprint(\"eps/|M|_F  = \", eps / np.linalg.norm(M, ord=\"fro\"))\n\nprint(\"Executing Proximal Projection\")\nL_pp, S_pp, res_pp, viol_pp, obj_pp = PP(M, lambd, eps, iters=iters, verbose=True)\nprint(\"Executing Variant Alternating Splitting Augmented Lagrangian Method\")\n_, _, res_vasalm, viol_vasalm, obj_vasalm = VASALM(M, lambd, eps, iters=iters, verbose=True)\nprint(\"Executing Smoothed Proximal Gradient\")\n_, _, res_spg, viol_spg, obj_spg = SPG(M, lambd, eps, iters=iters, verbose=True)\n</pre> iters = 30 lambd = (M.shape[0]) ** -0.5 eps = 0.10 * (M.size**0.5) * np.std(M) print(\"eps/|M|_F  = \", eps / np.linalg.norm(M, ord=\"fro\"))  print(\"Executing Proximal Projection\") L_pp, S_pp, res_pp, viol_pp, obj_pp = PP(M, lambd, eps, iters=iters, verbose=True) print(\"Executing Variant Alternating Splitting Augmented Lagrangian Method\") _, _, res_vasalm, viol_vasalm, obj_vasalm = VASALM(M, lambd, eps, iters=iters, verbose=True) print(\"Executing Smoothed Proximal Gradient\") _, _, res_spg, viol_spg, obj_spg = SPG(M, lambd, eps, iters=iters, verbose=True) In\u00a0[13]: Copied! <pre>import matplotlib.pyplot as plt\n\nfig, ax = plt.subplots()\nplt.title(\"Violation $\\\\frac{\\\\max\\\\{0,|X^k_L + X^k_S - M|_F- \\\\varepsilon\\\\}}{\\\\varepsilon}$\")\nplt.plot(viol_pp, color=\"b\")\nplt.plot(viol_vasalm, color=\"r\")\nplt.plot(viol_spg, color=\"k\")\nplt.yscale(\"log\")\nplt.show()\n\nfig, ax = plt.subplots()\nplt.title(\"Objective $|X^k_L|_* + \\\\lambda |X^k_S|_1$\")\nplt.plot(obj_pp, color=\"b\")\nplt.plot(obj_vasalm, color=\"r\")\nplt.plot(obj_spg, color=\"k\")\nplt.show()\n\nfig, ax = plt.subplots()\nplt.title(\"Residual $\\\\frac{|X^{k+1}-X^k|_F}{|M|_F}$\")\nplt.plot(res_pp, color=\"b\")\nplt.plot(res_vasalm, color=\"r\")\nplt.plot(res_spg, color=\"k\")\nplt.yscale(\"log\")\nplt.show()\n</pre> import matplotlib.pyplot as plt  fig, ax = plt.subplots() plt.title(\"Violation $\\\\frac{\\\\max\\\\{0,|X^k_L + X^k_S - M|_F- \\\\varepsilon\\\\}}{\\\\varepsilon}$\") plt.plot(viol_pp, color=\"b\") plt.plot(viol_vasalm, color=\"r\") plt.plot(viol_spg, color=\"k\") plt.yscale(\"log\") plt.show()  fig, ax = plt.subplots() plt.title(\"Objective $|X^k_L|_* + \\\\lambda |X^k_S|_1$\") plt.plot(obj_pp, color=\"b\") plt.plot(obj_vasalm, color=\"r\") plt.plot(obj_spg, color=\"k\") plt.show()  fig, ax = plt.subplots() plt.title(\"Residual $\\\\frac{|X^{k+1}-X^k|_F}{|M|_F}$\") plt.plot(res_pp, color=\"b\") plt.plot(res_vasalm, color=\"r\") plt.plot(res_spg, color=\"k\") plt.yscale(\"log\") plt.show() In\u00a0[14]: Copied! <pre>save_sample(M, L_pp, S_pp, frame=85)\n\nfilename = \"../results/spcp-obj-plots.csv\"\nwith open(filename, \"w\") as csv_file:\n    for k in range(len(obj_pp)):\n        csv_file.write(\"%0.5e,%0.5e,%0.5e\\n\" % (obj_pp[k], obj_vasalm[k], obj_spg[k]))\nfilename = \"../results/spcp-res-plots.csv\"\nwith open(filename, \"w\") as csv_file:\n    for k in range(len(res_pp)):\n        csv_file.write(\"%0.5e,%0.5e,%0.5e\\n\" % (res_pp[k], res_vasalm[k], res_spg[k]))\nfilename = \"../results/spcp-viol-plots.csv\"\nwith open(filename, \"w\") as csv_file:\n    for k in range(len(viol_pp)):\n        csv_file.write(\"%0.5e,%0.5e,%0.5e\\n\" % (viol_pp[k], viol_vasalm[k], viol_spg[k]))\n</pre> save_sample(M, L_pp, S_pp, frame=85)  filename = \"../results/spcp-obj-plots.csv\" with open(filename, \"w\") as csv_file:     for k in range(len(obj_pp)):         csv_file.write(\"%0.5e,%0.5e,%0.5e\\n\" % (obj_pp[k], obj_vasalm[k], obj_spg[k])) filename = \"../results/spcp-res-plots.csv\" with open(filename, \"w\") as csv_file:     for k in range(len(res_pp)):         csv_file.write(\"%0.5e,%0.5e,%0.5e\\n\" % (res_pp[k], res_vasalm[k], res_spg[k])) filename = \"../results/spcp-viol-plots.csv\" with open(filename, \"w\") as csv_file:     for k in range(len(viol_pp)):         csv_file.write(\"%0.5e,%0.5e,%0.5e\\n\" % (viol_pp[k], viol_vasalm[k], viol_spg[k]))"},{"location":"notebooks/stable_principal_component_pursuit/#principal-component-pursuit","title":"Principal Component Pursuit\u00b6","text":""},{"location":"notebooks/stable_principal_component_pursuit/#prepare-dataset","title":"Prepare Dataset\u00b6","text":"<p>Extract images from PNNL Parking Lot 1 dataset (video file).</p>"},{"location":"notebooks/stable_principal_component_pursuit/#load-images-into-matrix","title":"Load Images into Matrix\u00b6","text":""},{"location":"notebooks/stable_principal_component_pursuit/#execute-solvers","title":"Execute Solvers\u00b6","text":""},{"location":"notebooks/stable_principal_component_pursuit/#execute-experiment","title":"Execute Experiment\u00b6","text":""},{"location":"notebooks/stable_principal_component_pursuit/#plot-results","title":"Plot Results\u00b6","text":""},{"location":"notebooks/stable_principal_component_pursuit/#save-results","title":"Save Results\u00b6","text":""}]}